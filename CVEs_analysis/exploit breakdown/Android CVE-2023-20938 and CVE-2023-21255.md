Slides: https://androidoffsec.withgoogle.com/posts/attacking-android-binder-analysis-and-exploitation-of-cve-2023-20938/offensivecon_24_binder.pdf
Talk Video: https://www.youtube.com/watch?v=U-xSM159YLI
Additional article: https://androidoffsec.withgoogle.com/posts/attacking-android-binder-analysis-and-exploitation-of-cve-2023-20938/

# Bug
When sending a binder message to another process, if an error occurs, already sent binder objects need to be cleaned up in the receiving process (for example if some file descriptors are sent to new process, then an error occurs, the already sent ones are closed). However, there is a bug in `binder_transaction_buffer_release`, which is the function responsible for cleaning up sent objects. If no objects have been sent when the error occurs, it will clean up every object in the buffer. This can lead to cleaning up objects which were never sent. In the case of a `BINDER_TYPE_BINDER` object, it leads to decrementing the reference count of a binder node, which can lead to a UAF on a binder node.

At some point on later kernels, a patch was added that binder objects are copied in as they are processed, so no objects are in the binder buffer if an error occurs before any are copied over. However, another bug was discovered where the buffer is not zeroed on the end of a message. So sending a valid message, then sending an invalid message can have the same effect as the previous bug.

# Exploit
No code is available from what I can tell, so this is just rough overview of slides and talk:
- Create 2 tasks, which will communicate with each other using binder
	- Task A creates a binder node and sends a reference of it to task B
- Allocate many additional binder nodes, to fill an entire page of slab allocator with binder nodes
- Use bug to erroneously decrement recount on binder node object
	- Task B triggers the bug, by sending message with an offset length buffer not aligned to 8 byte size
	- Task A now has 1 message in its queue referencing freed object
- Free all other binder nodes to perform cross cache attack
- Reclaim binder node with `struct epitem` (stored in a linked list of `struct file` for epoll functionality)
	- `struct epitem` is on its own cache, so that is why cross cache attack is needed
	- `struct epitem` should be added with 2 per file descriptor (so file list has 2 epitem)
		- not explicitly stated in article but Im guessing thats how they did it based on other requirements
- Task A can leak prev and next pointer by receiving pending message pointing to freed and reclaimed binder node
	- When receiving a binder object, 2 values are read from node and passed 2 reciever
		- `ptr` and `cookie`, which are next to each other
		- Also overlap with linked list entry in `struct epitem`, so effectively it leaks prev and next pointer of `struct epitem`
		- This leaks address of `struct file` and another `struct epitem`
- Perform same bug again with 1 binder node, but this time reclaim with `struct msg_msg`
	- Inside `msg_msg`, create fake binder node with refcount of 1
	- After message received, kernel will decrement refcount of fake binder node again, and try to free it again (which will free `msg_msg`)
		- While freeing fake node, kernel remove it from a linked list
		- Since prev and next pointer of linked list can be controlled in `msg_msg`, this allows overwriting 8 bytes of memory as kernel updates linked list pointers as shown below:
```c
static inline void __hlist_del(struct hlist_node *n)
{
	struct hlist_node *next = n->next;
	struct hlist_node **pprev = n->pprev;

	WRITE_ONCE(*pprev, next);
	if (next)
		WRITE_ONCE(next->pprev, pprev);
}
```
- Arbitrary read
	- Use above write to overwrite `struct file` inode field to point at some offset to the leaked `struct epitem`
		- using `ioctl(fd, FGETBSZ, &alue)` uses inode pointer to find inode, then uses pointer in inode to find superblock to read block size
		- At the offset of super block pointer there is a controllable field which can be updated, so this can be used to get arbitrary read
- Set task to root
	- Use arbitrary read to find task `struct cread`
		- NOTE: slides stay they start with `struct binder_node` address and follow pointers to find task struct and credentials
			- Im not sure exactly how they leaked binder node address, perhaps returned `ptr` value under normal operation is actually pointer to binder node?
				- or perhaps they can get leak address of epitem, and since it was used to reclaim nodes, a nearby node data can be found?
			- It is still easy to leak in other ways though, for example you can leak KASLR with `struct file_operations`, read through list of tasks which is stored in kernel global data, and find your own taks based on pid, and find the credentials from that
	- Use previous linked list trick to write 0 to user id to make task root
	- Write 0 to `selinux_state.enforcing` to turn off selinux