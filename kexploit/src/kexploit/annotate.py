from pathlib import Path
from typing import Optional
import os

from openai import OpenAI
from pydantic import BaseModel

from .kernel_image import KernelImage
from .parse import Literal, Token, LexedCode, ReplaceResult, AnnotationType, SrcMetadata, ExploitFileGroup
from .rewrite_rules import is_annotated
from .tui import console

SYSTEM_PROMPT = '''
You are a model which analyses exploits for the linux kernel. These exploits depend on addresses, offsets, and struct field offsets in the linux kernel to work.
You should find all these addresses, and output JSON data containing a list of these addresses, offsets, and struct field offsets?

Addresses are 64 bit absolute virtual kernel addresses, typically with many leading 0xffffff bits, and have a type of `address`.
Offsets are offsets relative to the base of the kernel executable, and have a type of `offset`.
Struct field offsets are the offset from the start of a struct to a field in the struct. They are typically much smaller then offsets relative to the kernel base, typically less than 2048.
Struct field offsets have a type of `struct_offset`.

Report addresses and offsets exactly as they appear in the code. Don't try to compute offsets from the addresses present in the code, just report the address constants in the JSON data.

For example, for the given input code:
File main.c:
```
#define A 0xffffffc010020f58
#define B_OFFSET 0x120

int main() {
    size_t c = 0xffffffc092004cd0;
    size_t d_offset = 0x34980;
    size_t z_offset = A - 0xffffffc088084000;
}
```
File exploit.h:
```
#define M_PTR 0x68
#define TIMERFD_FOPS_OFFSET 0x149828
```

The corresponding JSON data is:
```
[
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc010020f58"
    },
    {
        "file": "main.c",
        "type": "struct_offset",
        "value": "0x120"
    },
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc092004cd0"
    },
    {
        "file": "main.c",
        "type": "offset",
        "value": "0x34980"
    },
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc088084000"
    },
    {
        "file": "exploit.h",
        "type": "struct_offset",
        "value": "0x68"
    },
    {
        "file": "exploit.h",
        "type": "offset",
        "value": "0x149828"
    }
]
```

You will be given C code from several files, and should output only the JSON data.
'''
MODEL = 'gpt-4.1-mini'

class AnnotateContext:
    kernel_image: KernelImage
    files: ExploitFileGroup

    def __init__(self, files: list[Path], kernel_name: str):
        # mapping from filename to file lexed file content
        self.files = ExploitFileGroup(files)
        self.kernel_image = KernelImage(kernel_name)

class KernelOffset(BaseModel):
    file: str
    # either `address`, `offset`, or `struct_offset`
    type: str
    value: str

class AnnotationData(BaseModel):
    data: list[KernelOffset]

def get_chatgpt_completions(context: AnnotateContext) -> dict[tuple[str, int], AnnotationType]:
    prompt = ''
    for file in context.files.lexed_code():
        prompt += f'File: {os.path.basename(file.filename)}\n`{file.code}`\n'
    
    # TODO: use json schema
    response = OpenAI().responses.parse(
        model=MODEL,
        instructions=SYSTEM_PROMPT,
        input=prompt,
        text_format=AnnotationData,
    )

    annotation_map = {}
    for offset in response.output_parsed.data:
        try:
            n = int(offset.value, 0)
        except:
            # only consider things chatgpt reports which are just integer constants for now
            continue

        match offset.type:
            case 'address':
                annotation = AnnotationType.KEXPLOIT_ADDRESS
            case 'offset':
                annotation = AnnotationType.KEXPLOIT_OFFSET
            case 'struct_offset':
                # ignore struct offsets for now
                continue
                # annotation = KEXPLOIT_STRUCT_OFFSET
            case _:
                # if invalid type ignore
                print(f'Warning: invalid offset type received from LLM: {offset.type}')
                continue

        annotation_map[(offset.file, n)] = annotation
    
    return annotation_map

def annotate(exploit_files: list[Path], kernel_name: str, diff_output: Path, apply_diff: bool):
    context = AnnotateContext(exploit_files, kernel_name)
    metadata = SrcMetadata(
        original_kernel_name=kernel_name,
        current_kernel_name=kernel_name,
    )
    
    annotation_map = get_chatgpt_completions(context)

    def rewrite_file(lexed_file: LexedCode) -> Optional[str]:
        if lexed_file.is_annotated():
            console.error(f'{lexed_file.filename} is already annotated')
            return None
        
        def do_annotate(tokens: list[Token], index: int) -> ReplaceResult:
            match tokens[index].data:
                case Literal(int(value)):
                    # don't annotate if already annotated
                    if is_annotated(tokens, index):
                        return ReplaceResult.skip()
                    
                    # if context.kernel_image.arch_info.is_kernel_address(value):
                    #     return ReplaceResult.replace(1, f'{KEXPLOIT_ADDRESS}({hex(value)})')

                    annotation = annotation_map.get((os.path.basename(lexed_file.filename), value))
                    if annotation is None:
                        return ReplaceResult.skip()
                    
                    if annotation == AnnotationType.KEXPLOIT_ADDRESS:
                        rop_gadget = context.kernel_image.get_rop_chain_instructions(value)
                        
                        if rop_gadget is not None:
                            return ReplaceResult.replace(1, f'{AnnotationType.KEXPLOIT_ROP_ADDRESS}({hex(value)}, "{rop_gadget}")')

                    elif annotation == AnnotationType.KEXPLOIT_OFFSET:
                        rop_gadget = context.kernel_image.get_rop_chain_instructions_offset(value)

                        if rop_gadget is not None:
                            return ReplaceResult.replace(1, f'{AnnotationType.KEXPLOIT_ROP_OFFSET}({hex(value)}, "{rop_gadget}")')
                    
                    return ReplaceResult.replace(1, f'{annotation}({hex(value)})')

            return ReplaceResult.skip()
        
        annotated_code, errors = lexed_file.replace_tokens(do_annotate)
        # TODO: don't always put metadata at bottom because it might be outside of ifdef or something
        # Also don't include kexploit.h if it is already included
        annotated_code = f'#include "kexploit.h"\n{metadata.to_annotation()}\n{annotated_code}'
        console.print_errors(errors)

        return annotated_code
    
    context.files.rewrite_files(rewrite_file, diff_output, apply_diff)