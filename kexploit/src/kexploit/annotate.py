from pathlib import Path
from typing import Optional
from difflib import unified_diff
import os
from dataclasses import dataclass

from openai import OpenAI
from pydantic import BaseModel

from .kernel_image import KernelImage
from .parse import Literal, Token, lex, LexedCode
from .rewrite_rules import is_annotated, KEXPLOIT_ADDRESS, KEXPLOIT_OFFSET, KEXPLOIT_ROP_ADDRESS, KEXPLOIT_ROP_OFFSET

SYSTEM_PROMPT = '''
You are a model which analyses exploits for the linux kernel. These exploits depend on addresses, offsets, and struct field offsets in the linux kernel to work.
You should find all these addresses, and output JSON data containing a list of these addresses, offsets, and struct field offsets?

Addresses are 64 bit absolute virtual kernel addresses, typically with many leading 0xffffff bits, and have a type of `address`.
Offsets are offsets relative to the base of the kernel executable, and have a type of `offset`.
Struct field offsets are the offset from the start of a struct to a field in the struct. They are typically much smaller then offsets relative to the kernel base, typically less than 2048.
Struct field offsets have a type of `struct_offset`.

Report addresses and offsets exactly as they appear in the code. Don't try to compute offsets from the addresses present in the code, just report the address constants in the JSON data.

For example, for the given input code:
File main.c:
```
#define A 0xffffffc010020f58
#define B_OFFSET 0x120

int main() {
    size_t c = 0xffffffc092004cd0;
    size_t d_offset = 0x34980;
    size_t z_offset = A - 0xffffffc088084000;
}
```
File exploit.h:
```
#define M_PTR 0x68
#define TIMERFD_FOPS_OFFSET 0x149828
```

The corresponding JSON data is:
```
[
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc010020f58"
    },
    {
        "file": "main.c",
        "type": "struct_offset",
        "value": "0x120"
    },
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc092004cd0"
    },
    {
        "file": "main.c",
        "type": "offset",
        "value": "0x34980"
    },
    {
        "file": "main.c",
        "type": "address",
        "value": "0xffffffc088084000"
    },
    {
        "file": "exploit.h",
        "type": "struct_offset",
        "value": "0x68"
    },
    {
        "file": "exploit.h",
        "type": "offset",
        "value": "0x149828"
    }
]
```

You will be given C code from several files, and should output only the JSON data.
'''
MODEL = 'gpt-4.1-mini'

class AnnotateContext:
    kernel_image: KernelImage
    files: dict[str, LexedCode]

    def __init__(self, kernel: Path):
        # mapping from filename to file lexed file content
        self.files = {}
        self.kernel_image = KernelImage.from_file(kernel)

class KernelOffset(BaseModel):
    file: str
    # either `address`, `offset`, or `struct_offset`
    type: str
    value: str

class AnnotationData(BaseModel):
    data: list[KernelOffset]

def get_chatgpt_completions(context: AnnotateContext) -> dict[tuple[str, int], str]:
    prompt = ''
    for file_name, file_data in context.files.items():
        prompt += f'File: {os.path.basename(file_name)}\n`{file_data.code}`\n'
    
    # TODO: use json schema
    response = OpenAI().responses.parse(
        model=MODEL,
        instructions=SYSTEM_PROMPT,
        input=prompt,
        text_format=AnnotationData,
    )

    annotation_map = {}
    for offset in response.output_parsed.data:
        try:
            n = int(offset.value, 0)
        except:
            # only consider things chatgpt reports which are just integer constants for now
            continue

        match offset.type:
            case 'address':
                annotation = KEXPLOIT_ADDRESS
            case 'offset':
                annotation = KEXPLOIT_OFFSET
            case 'struct_offset':
                # ignore struct offsets for now
                continue
                # annotation = KEXPLOIT_STRUCT_OFFSET
            case _:
                # if invalid type ignore
                print(f'Warning: invalid offset type received from LLM: {offset.type}')
                continue

        annotation_map[(offset.file, n)] = annotation
    
    return annotation_map

def annotate(exploit_files: list[Path], kernel: Path, apply: bool):
    diff = ''
    context = AnnotateContext(kernel)

    for file in exploit_files:
        # if kexploit.h is globbed in exploit_files, ignore
        if os.path.basename(file) == 'kexploit.h':
            continue

        with open(file, 'r') as f:
            exploit_code = f.read()

        context.files[file] = lex(file, exploit_code)
    
    annotation_map = get_chatgpt_completions(context)
    print(annotation_map)

    for lexed_file in context.files.values():
        def do_annotate(tokens: list[Token], index: int) -> Optional[tuple[int, str]]:
            match tokens[index].data:
                case Literal(int(value)):
                    # don't annotate if already annotated
                    if is_annotated(tokens, index):
                        return None
                    
                    if context.kernel_image.arch_info.is_kernel_address(value):
                        return 1, f'{KEXPLOIT_ADDRESS}({hex(value)})'

                    annotation = annotation_map.get((os.path.basename(lexed_file.filename), value))
                    if annotation is None:
                        return None
                    
                    if annotation == KEXPLOIT_ADDRESS and context.kernel_image.is_rop_chain_address(value):
                        gadget = context.kernel_image.get_rop_chain_instructions(value)

                        return 1, f'{KEXPLOIT_ROP_ADDRESS}({hex(value)}, "{gadget}")'
                    elif annotation == KEXPLOIT_OFFSET and context.kernel_image.is_rop_chain_offset(value):
                        gadget = context.kernel_image.get_rop_chain_instructions_offset(value)

                        return 1, f'{KEXPLOIT_ROP_OFFSET}({hex(value)}, "{gadget}")'
                    else:
                        return 1, f'{annotation}({hex(value)})'

            return None
        
        annotated_code = lexed_file.replace_tokens(do_annotate)

        # diff just for user
        for diff_line in unified_diff(
            lexed_file.code.split('\n'),
            annotated_code.split('\n'),
            fromfile=str(lexed_file.filename),
            tofile=str(lexed_file.filename),
            lineterm='',
        ):
            diff += diff_line + '\n'

        if apply:
            with open(lexed_file.filename, 'w') as f:
                f.write(annotated_code)
    
    print(diff)