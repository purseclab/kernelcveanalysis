# Pulls buts from syzkaller syzbot and filters for interesting looking ones

from typing import Optional, Self
from dataclasses import dataclass
from pathlib import Path
import os
import sqlite3
from datetime import datetime
import time

from bs4 import BeautifulSoup, Tag
import requests

class CachedObject:
    url: str
    data: Optional[str]

    def __init__(self, url: str):
        self.url = url
        self.data = None
    
    def get_object(self) -> str:
        if self.data is None:
            self.data = requests.get(self.url).text
        return self.data

def get_tag_string(tag: Tag) -> str:
    return ' '.join(tag.find_all(string=True)).strip()

def parse_table_row(row: Tag, header=False) -> list[Tag]:
    assert row.name == 'tr'
    look_tag = 'th' if header else 'td'
    return row.find_all(look_tag)

def parse_table_row_strings(row: Tag, header=False) -> list[str]:
    return [get_tag_string(entry.find(name=True)) for entry in parse_table_row(row, header)]

def parse_table(table: Tag) -> list[dict[str, Tag]]:
    assert table.name == 'table'
    header_values = ['_'.join(value.lower().split()) for value in parse_table_row_strings(table.thead.tr, header=True)]
    
    output = []
    for row in table.tbody.find_all(name='tr'):
        row = parse_table_row(row)
        row_data = {}

        for header, row_value in zip(header_values, row):
            row_data[header] = row_value
        
        output.append(row_data)
            
    return output

# find a table based on if the name in the name in the caption element contains `name_part`
def find_table_by_name(html: BeautifulSoup, name_part: str) -> Tag:
    for caption in html.find_all('caption'):
        if name_part.lower() in get_tag_string(caption).lower():
            parent = caption.parent
            if parent.name == 'table':
                return parent

    return None

def path_to_syzkall_url(url_path: str) -> str:
    return f'https://syzkaller.appspot.com/{url_path}'

def get_syzkall_html(url_path: str) -> BeautifulSoup:
    response = requests.get(path_to_syzkall_url(url_path))
    return BeautifulSoup(response.text, 'html.parser')

# filters for bugs which are potentially exploitable
def filter_bugs(data: list[dict[str, Tag]]) -> list[dict[str, Tag]]:
    # we are only interested in bugs with a reproduction
    data = [row for row in data if get_tag_string(row['repro']) == 'C']
    
    # look for bugs that look exploitable
    # for now that just means is KASAN in the title, since that is typically memory unsafety issue
    data = [row for row in data if 'KASAN' in get_tag_string(row['title'])]
    return data

@dataclass
class BugMetadata:
    bug_id: str

    description: str
    # stored in database as comma seperated string
    subsystems: list[str]
    # TODO: store as Date object
    # for now just use date string reported by syzkaller
    crash_time: datetime

    # name of kernel pulled from syzkaller
    kernel_name: str
    # link to git commit with kernel src
    kernel_url: str
    kernel_config_url: str

    crash_report: str
    c_repro_url: str
    disk_image_url: str
    disk_image_is_bootable: bool
    kernel_image_url: str
    vmlinux_url: str

class SyzkallBugDatabase:
    base_folder: Path
    metadata_db: sqlite3.Connection

    def __init__(self, base_folder: Path):
        self.base_folder = base_folder
        self.base_folder.mkdir(parents=True, exist_ok=True)

        self.metadata_db = sqlite3.connect(os.path.join(self.base_folder, 'metadata_db.sqlite'))
        self.metadata_db.execute('''
        CREATE TABLE IF NOT EXISTS bugs (
            id TEXT PRIMARY KEY,
            description TEXT,
            subsystems TEXT,
            crash_time TIMESTAMP,
            kernel_name TEXT,
            kernel_url TEXT,
            kernel_config_url TEXT,
            crash_report TEXT,
            c_repro_url TEXT,
            disk_image_url TEXT,
            disk_image_is_bootable INTEGER,
            kernel_image_url TEXT,
            vmlinux_url TEXT
        )
        ''')
    
    def close(self):
        self.metadata_db.close()
    
    def save_bug_metadata(self, metadata: BugMetadata):
        self.metadata_db.execute('''
        INSERT INTO bugs (
            id,
            description,
            subsystems,
            crash_time,
            kernel_name,
            kernel_url,
            kernel_config_url,
            crash_report,
            c_repro_url,
            disk_image_url,
            disk_image_is_bootable,
            kernel_image_url,
            vmlinux_url
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            metadata.bug_id,
            metadata.description,
            ','.join(metadata.subsystems),
            metadata.crash_time,
            metadata.kernel_name,
            metadata.kernel_url,
            metadata.kernel_config_url,
            metadata.crash_report,
            metadata.c_repro_url,
            metadata.disk_image_url,
            metadata.disk_image_is_bootable,
            metadata.kernel_image_url,
            metadata.vmlinux_url,
        ))
        self.metadata_db.commit()
    
    def get_bug_metadata(self, id: str) -> Optional[BugMetadata]:
        result = self.metadata_db.execute('SELECT * FROM bugs WHERE id = ?', (id,)).fetchone()
        if result is None:
            return None
        
        return BugMetadata(
            bug_id=result[0],
            description=result[1],
            subsystems=result[2].split(','),
            crash_time=result[3],
            kernel_name=result[4],
            kernel_url=result[5],
            kernel_config_url=result[6],
            crash_report=result[7],
            c_repro_url=result[8],
            disk_image_url=result[9],
            disk_image_is_bootable=(result[10] == 1),
            kernel_image_url=result[12],
            vmlinux_url=result[12],
        )

def bug_id_from_url(url_path: str) -> str:
    return url_path.split('=')[1].strip()

def download_bug_metadata(bug: dict[str, Tag]) -> Optional[BugMetadata]:
    url = bug['title'].a['href']
    bug_page = get_syzkall_html(url)
    table = parse_table(find_table_by_name(bug_page, 'crashes'))

    for c_repro_row in table:
        if get_tag_string(c_repro_row['c_repro']) != 'C':
            continue

        # asset paths are full url to google cloud bucket, not relative path like c_repro_path
        assets = c_repro_row['assets']

        disk_image_str = assets.find(string='disk image')
        disk_image_non_bootable = assets.find(string='disk image (non-bootable)')

        # use non bootable image if bootable one does not exist
        disk_image_is_bootable = True
        if disk_image_str is None and disk_image_non_bootable is not None:
            disk_image_str = disk_image_non_bootable
            disk_image_is_bootable = False

        vmlinux_str = assets.find(string='vmlinux')
        kernel_image_str = assets.find(string='kernel image')

        if disk_image_str is None or vmlinux_str is None or kernel_image_str is None:
            continue

        disk_image_path = disk_image_str.parent['href']
        vmlinux_path = vmlinux_str.parent['href']
        kernel_image_path = kernel_image_str.parent['href']
        
        # title contains subsystems, without false positives
        subsystems = [get_tag_string(span) for span in bug['title'].find_all(name='span', attrs={'class': 'bug-label'})]

        c_repro_path = path_to_syzkall_url(c_repro_row['c_repro'].a['href'])
        kernel_config_url = path_to_syzkall_url(c_repro_row['config'].a['href'])

        crash_report = get_tag_string(bug_page.pre)

        crash_time_string = get_tag_string(c_repro_row['time'])
        crash_time = datetime.strptime(crash_time_string, '%Y/%m/%d %H:%M')

        return BugMetadata(
            bug_id=bug_id_from_url(url),
            description=get_tag_string(c_repro_row['title']),
            subsystems=subsystems,
            crash_time=crash_time,
            kernel_name=get_tag_string(c_repro_row['kernel']),
            kernel_url=c_repro_row['commit'].a['href'],
            kernel_config_url=kernel_config_url,
            crash_report=crash_report,
            c_repro_url=c_repro_path,
            disk_image_url=disk_image_path,
            disk_image_is_bootable=disk_image_is_bootable,
            kernel_image_url=kernel_image_path,
            vmlinux_url=vmlinux_path,
        )
    
    return None

# kernel_name is upstream for default linux
# can also be android
def get_bugs_for_kernel(kernel_name: str) -> tuple[list[dict[str, Tag]], list[dict[str, Tag]]]:
    open_bugs_table = find_table_by_name(get_syzkall_html(kernel_name), 'open')
    fixed_bugs_table = get_syzkall_html(f'{kernel_name}/fixed').find_all(name='table')[1]

    bugs_open = filter_bugs(parse_table(open_bugs_table))
    bugs_fixed = filter_bugs(parse_table(fixed_bugs_table))

    return bugs_open, bugs_fixed

def pull(kernel_name: str, bug_path: Path):
    bugs_open, bugs_fixed = get_bugs_for_kernel(kernel_name)
    bugs_combined = bugs_open + bugs_fixed

    db = SyzkallBugDatabase(bug_path)

    try:
        for bug in bugs_combined:
            print('Pulling:')
            print(get_tag_string(bug['title']).replace('\n', ' '))

            url = bug['title'].a['href']
            id = bug_id_from_url(url)
            if db.get_bug_metadata(id) is not None:
                print('already downloaded')
                continue

            bug_metadata = download_bug_metadata(bug)
            time.sleep(3)
            if bug_metadata is None:
                print('Failed to parse')
                continue
            db.save_bug_metadata(bug_metadata)
    finally:
        db.close()
    