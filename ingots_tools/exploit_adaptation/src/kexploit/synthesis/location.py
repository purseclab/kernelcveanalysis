from dataclasses import dataclass
import hashlib
import re
from typing import Self, TYPE_CHECKING

from multilspy.multilspy_types import Location as MultilspyLocation

if TYPE_CHECKING:
    from .synthesis_metadata import SynthesisMetadata

@dataclass
class Position:
    line: int
    column: int

@dataclass
class Location:
    file_path: str
    start: Position
    end: Position

    @classmethod
    def from_str(cls, s: str) -> Self:
        # 1. Strip potential quotes if the CSV parser didn't catch them
        s = s.strip('"')
        
        # 2. Match: Optional file:// prefix, then path, then 4 colon-separated numbers
        # in docker source code is in src directory, so remove src as well
        pattern = r"^(?:file:///src/)?(.*?):(\d+):(\d+):(\d+):(\d+)$"
        match = re.match(pattern, s)
        
        if not match:
            # Fallback for unexpected formats
            return cls(file_path=s, start=Position(0, 0), end=Position(0, 0))
        
        path, l1, c1, l2, c2 = match.groups()
        
        return cls(
            file_path=path,
            start=Position(
                line=int(l1),
                column=int(c1),
            ),
            end=Position(
                line=int(l2),
                column=int(c2),
            )
        )
    
    @classmethod
    def from_multilspy_location(cls, location: MultilspyLocation) -> Self:
        # LSP uses 0-indexed lines and columns. We convert to 1-indexed for consistency.
        return cls(
            file_path=location['relative_path'],
            start=Position(
                line=location['range']['start']['line'] + 1,
                column=location['range']['start']['character'] + 1,
            ),
            end=Position(
                line=location['range']['end']['line'] + 1,
                column=location['range']['end']['character'] + 1,
            ),
        )

    def __str__(self):
        """Full string representation for round-tripping data."""
        return f"{self.file_path}:{self.start.line}:{self.start.column}:{self.end.line}:{self.end.column}"
    
    def to_db_id(self) -> int:
        digest = hashlib.sha256(str(self).encode()).hexdigest()
        return int(digest, 16) & (2**63 - 1)

    def read_source(self, metadata: 'SynthesisMetadata') -> str:
        """Reads the source code content for this location from the kernel source directory."""
        path = metadata.linux_src / self.file_path
        if not path.exists():
            return f'/* Error: File {path} not found */'
        
        try:
            with open(path, 'r', encoding='utf-8', errors='replace') as f:
                lines = f.readlines()
        except Exception as e:
            return f'/* Error reading file: {e} */'

        if not lines:
            return ''

        # Adjust 1-indexed to 0-indexed for array access
        s_line = max(0, self.start.line - 1)
        s_col = max(0, self.start.column - 1)
        e_line = min(len(lines) - 1, self.end.line - 1)
        e_col = self.end.column # Keep as is, column indices in slices are usually exclusive-end

        if s_line >= len(lines):
            return f'/* Error: start line {self.start.line} out of range */'

        if s_line == e_line:
            return lines[s_line][s_col:e_col]
        
        res = []
        res.append(lines[s_line][s_col:])
        for i in range(s_line + 1, e_line):
            res.append(lines[i])
        res.append(lines[e_line][:e_col])
        
        return ''.join(res)