"""
exploit.pipeline — End-to-end exploit generation pipeline.

Orchestrates: plan → resolve kernel offsets → generate code → validate → compile → verify.
"""

from __future__ import annotations

import glob
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

from ..core.config import Config, load_config
from ..core.log import console
from ..core.models import Arch, ExploitResult, Platform, VerificationAttempt
from ..orchestrator.context import TaskContext
from ..reproducer.compiler import compile_reproducer
from .planner import plan_exploit
from .generator import generate_exploit_code, review_exploit_code
from .stitcher import stitch_exploit
from .code_validator import validate_exploit_code, ValidationResult


# ── Exploitation technique formatting ────────────────────────────────


def _format_exploitation_details(details: Dict[str, Any]) -> str:
    """Format exploitation_details dict into a structured prompt section."""
    if not details:
        return ""

    lines = ["=== EXPLOITATION TECHNIQUE DETAILS (from blog analysis) ==="]
    lines.append("IMPORTANT: Follow these technique details closely when")
    lines.append("writing the exploit. They describe what WORKS for this CVE.")
    lines.append("")

    field_labels = {
        "device_or_interface": "Device/Interface",
        "trigger_method": "Vulnerability Trigger Method",
        "uaf_object_type": "UAF Object (type & size)",
        "reclaim_object_type": "Reclaim Object (for cross-cache)",
        "leak_method": "Kernel Address Leak Method",
        "rw_primitive_method": "Arbitrary R/W Primitive",
        "process_architecture": "Process Architecture",
        "service_discovery": "Service Discovery Method",
        "privilege_escalation_path": "Privilege Escalation Path",
        "heap_spray_details": "Heap Spray Strategy",
    }

    for key, label in field_labels.items():
        val = details.get(key, "")
        if val:
            lines.append(f"  {label}: {val}")

    # Kernel structs exploited
    structs = details.get("kernel_structs_exploited", [])
    if structs:
        lines.append(f"  Kernel Structs Used: {', '.join(structs)}")

    # Key constants
    constants = details.get("key_constants", [])
    if constants:
        lines.append(f"  Key Constants: {'; '.join(constants)}")

    # Binder-specific details
    binder = details.get("binder_specific", {})
    if binder and any(binder.values()):
        lines.append("")
        lines.append("  BINDER-SPECIFIC:")
        if binder.get("binder_device"):
            lines.append(f"    Device: {binder['binder_device']}")
        if binder.get("uses_context_manager") is not None:
            lines.append(f"    Uses context manager: {binder['uses_context_manager']}")
        if binder.get("transaction_types"):
            lines.append(f"    Transaction types: {binder['transaction_types']}")
        if binder.get("vulnerability_in_function"):
            lines.append(f"    Vulnerable function: {binder['vulnerability_in_function']}")

    # Android-specific details
    android = details.get("android_specific", {})
    if android and any(android.values()):
        lines.append("")
        lines.append("  ANDROID-SPECIFIC:")
        for k, v in android.items():
            if v:
                lines.append(f"    {k}: {v}")

    # Code snippets from the blog
    snippets = details.get("code_snippets", [])
    if snippets:
        lines.append("")
        lines.append("  Key code patterns from the write-up:")
        for i, snippet in enumerate(snippets[:5], 1):
            lines.append(f"    Pattern {i}: {snippet[:500]}")

    lines.append("")
    return "\n".join(lines)


def _find_reference_exploit(ctx: TaskContext) -> str:
    """
    Search for a known working exploit for the same CVE in the
    kernel_PoCs directory and return key excerpts for the LLM.
    """
    if not ctx.root_cause:
        return ""

    # Extract CVE ID from the summary or context
    cve_id = ""
    summary = ctx.root_cause.summary or ""
    m = re.search(r"(CVE-\d{4}-\d+)", summary, re.IGNORECASE)
    if m:
        cve_id = m.group(1)
    if not cve_id and hasattr(ctx, "input_value"):
        m = re.search(r"(CVE-\d{4}-\d+)", str(getattr(ctx, "input_value", "")), re.IGNORECASE)
        if m:
            cve_id = m.group(1)
    if not cve_id:
        return ""

    # Search for reference exploits in known locations
    # Look in workspace for kernel_PoCs directory
    search_roots = [
        Path("/home/gl055/research/ingots/dev/kernelcveanalysis/kernel_PoCs"),
        Path.cwd().parent / "kernel_PoCs",
        Path.cwd().parent.parent / "kernel_PoCs",
    ]

    ref_dir = None
    cve_lower = cve_id.lower().replace("-", "_").replace("cve_", "cve-")
    cve_pattern = cve_id.lower().replace("-", "*")

    for root in search_roots:
        if not root.exists():
            continue
        # Search for directories matching the CVE
        for d in root.rglob("*"):
            if d.is_dir() and cve_lower.replace("cve-", "") in d.name.lower().replace("-", "_"):
                # Look for adapted version matching target kernel
                adapted = d / "adapted"
                if adapted.exists():
                    # Find the most relevant adaptation
                    for ad in adapted.iterdir():
                        if ad.is_dir():
                            ref_dir = ad
                            break
                if not ref_dir and (d / "exploit.c").exists():
                    ref_dir = d
                if ref_dir:
                    break
        if ref_dir:
            break

    if not ref_dir:
        return ""

    console.print(f"  [bold]Found reference exploit: {ref_dir}[/]")

    # Read key files and extract the most relevant portions
    lines = [
        "=== REFERENCE EXPLOIT (known working exploit for this CVE) ===",
        "The following excerpts are from a WORKING exploit for this exact CVE.",
        "Study them carefully and follow the same patterns.\n",
    ]

    # Read exploit.c (main exploit logic)
    exploit_c = ref_dir / "exploit.c"
    if exploit_c.exists():
        content = exploit_c.read_text()
        lines.append(f"--- exploit.c ({len(content)} bytes) ---")
        # Include the first part (struct definitions, setup) and key functions
        if len(content) > 4000:
            lines.append(content[:4000])
            lines.append("\n[...truncated...]\n")
        else:
            lines.append(content)
        lines.append("")

    # Read exploit.h (shared types, offsets)
    exploit_h = ref_dir / "exploit.h"
    if exploit_h.exists():
        content = exploit_h.read_text()
        lines.append(f"--- exploit.h ({len(content)} bytes) ---")
        lines.append(content[:2000])
        lines.append("")

    # Read binder_client.c if it exists (binder interaction)
    binder_c = ref_dir / "binder_client.c"
    if binder_c.exists():
        content = binder_c.read_text()
        lines.append(f"--- binder_client.c ({len(content)} bytes) ---")
        lines.append(content[:2000])
        lines.append("")

    # Read binder.h if it exists (struct definitions)
    binder_h = ref_dir / "binder.h"
    if binder_h.exists():
        content = binder_h.read_text()
        lines.append(f"--- binder.h ({len(content)} bytes) ---")
        lines.append(content[:2000])
        lines.append("")

    # Read Makefile
    makefile = ref_dir / "Makefile"
    if makefile.exists():
        content = makefile.read_text()
        lines.append(f"--- Makefile ---\n{content}\n")

    result = "\n".join(lines)
    if len(result) < 100:
        return ""

    console.print(f"  [dim]Reference exploit context: {len(result)} chars[/]")
    return result


# ── Structured verification feedback ─────────────────────────────────


def _analyze_exploit_phases(output: str) -> Dict[str, str]:
    """
    Analyze exploit stdout to determine which phases completed.

    Parses common exploit output patterns to identify:
      - Which phases ran successfully
      - Which phase the exploit got stuck on
      - Whether it hung, crashed, or ran to completion

    Returns a dict mapping phase names to status strings.
    """
    phases: Dict[str, str] = {}

    # Common exploit phase markers (case-insensitive)
    phase_patterns = [
        ("initialization", r'\[[\+\*]\].*(?:init|start|begin|setup)', r'\[-\].*(?:init|start|begin|setup)'),
        ("device_open", r'\[[\+\*]\].*(?:open|device|binder|driver|fd)', r'\[-\].*(?:open|device|binder|driver)'),
        ("trigger", r'\[[\+\*]\].*(?:trigger|vuln|bug|corrupt|exploit)', r'\[-\].*(?:trigger|vuln|bug|exploit)'),
        ("spray", r'\[[\+\*]\].*(?:spray|reclaim|alloc|slab|cross.?cache)', r'\[-\].*(?:spray|reclaim|alloc)'),
        ("leak", r'\[[\+\*]\].*(?:leak|kaslr|kernel.?base|addr)', r'\[-\].*(?:leak|kaslr|kernel.?base)'),
        ("rw_primitive", r'\[[\+\*]\].*(?:read|write|r/w|primitive|arb)', r'\[-\].*(?:read|write|r/w|primitive)'),
        ("cred_overwrite", r'\[[\+\*]\].*(?:cred|uid|privilege|root|overwrite)', r'\[-\].*(?:cred|uid|privilege|overwrite)'),
        ("uid_check", r'SYZPLOIT_UID_AFTER=0', r'SYZPLOIT_UID_AFTER=[1-9]'),
    ]

    for phase_name, success_re, failure_re in phase_patterns:
        if re.search(success_re, output, re.IGNORECASE):
            phases[phase_name] = "succeeded"
        elif re.search(failure_re, output, re.IGNORECASE):
            phases[phase_name] = "failed"

    # Detect overall outcome (crash takes priority over hung)
    output_lines = [l for l in output.strip().split("\n") if l.strip()]
    if re.search(r'(?:segfault|segmentation fault|signal|abort|killed)', output, re.IGNORECASE):
        phases["_overall"] = "crashed"
    elif len(output_lines) < 3:
        phases["_overall"] = "likely_hung"
    elif re.search(r'\[\+\]\s*SUCCESS\b', output, re.IGNORECASE):
        phases["_overall"] = "succeeded"
    else:
        phases["_overall"] = "ran_but_failed"

    return phases


def _build_structured_feedback(attempt) -> str:
    """
    Build structured feedback from a VerificationAttempt for the LLM.

    Instead of raw output, provides:
      1. Phase-by-phase analysis (what worked, what didn't)
      2. Specific failure mode (hung, crashed, wrong output)
      3. Actionable guidance for the next iteration
    """
    parts = []

    # Header
    parts.append("=== PREVIOUS EXPLOIT ATTEMPT FAILED ===")

    # Failure reason
    if attempt.failure_reason:
        parts.append(f"Failure: {attempt.failure_reason}")

    # Phase analysis from exploit output
    if attempt.exploit_output:
        phases = _analyze_exploit_phases(attempt.exploit_output)
        if phases:
            parts.append("\nExploit phase analysis:")
            for phase, status in phases.items():
                if phase == "_overall":
                    continue
                icon = "✓" if status == "succeeded" else "✗"
                parts.append(f"  {icon} {phase}: {status}")

            overall = phases.get("_overall", "unknown")
            if overall == "likely_hung":
                parts.append(
                    "\n⚠ The exploit appears to have HUNG (very little output)."
                    "\n  Common causes: blocking ioctl/read without a response,"
                    "\n  deadlock between processes, waiting for a condition that"
                    "\n  never occurs. Add timeouts and alarm() to prevent hangs."
                )
            elif overall == "crashed":
                parts.append(
                    "\n⚠ The exploit CRASHED (segfault/signal)."
                    "\n  The kernel address or offset used is likely wrong."
                    "\n  Verify all pointer arithmetic and kernel struct layouts."
                )
            elif overall == "ran_but_failed":
                # Find the last succeeded phase and first failed phase
                succeeded = [p for p, s in phases.items() if s == "succeeded" and p != "_overall"]
                failed = [p for p, s in phases.items() if s == "failed" and p != "_overall"]
                if succeeded and failed:
                    parts.append(
                        f"\n  Last succeeded phase: {succeeded[-1]}"
                        f"\n  First failed phase: {failed[0]}"
                        f"\n  → Focus fixes on the {failed[0]} phase."
                    )
                elif succeeded:
                    parts.append(
                        f"\n  Phases that worked: {', '.join(succeeded)}"
                        f"\n  The exploit ran past these but did not achieve privesc."
                    )

        # Include raw output (truncated)
        parts.append(f"\nExploit stdout/stderr (last 1500 chars):")
        parts.append(attempt.exploit_output[-1500:])

    # GDB trace info
    if hasattr(attempt, "gdb_functions_hit") and attempt.gdb_functions_hit:
        parts.append(f"\nGDB: functions HIT: {', '.join(attempt.gdb_functions_hit)}")
    if hasattr(attempt, "gdb_functions_missed") and attempt.gdb_functions_missed:
        parts.append(f"GDB: functions MISSED: {', '.join(attempt.gdb_functions_missed)}")
        # Give specific guidance if key functions weren't hit
        missed_set = set(attempt.gdb_functions_missed)
        if "commit_creds" in missed_set:
            parts.append(
                "  → commit_creds was NOT called — the exploit never reached"
                "  the privilege escalation stage. Fix the earlier phases first."
            )

    # dmesg
    if attempt.dmesg_new:
        parts.append(f"\ndmesg (new lines):\n{attempt.dmesg_new[:1500]}")

    # Existing feedback from verification module
    if attempt.feedback:
        parts.append(f"\nVerification feedback: {attempt.feedback}")

    parts.append(
        "\nYou MUST address ALL the issues above in the regenerated code. "
        "Do NOT repeat the same mistakes."
    )

    return "\n".join(parts)


def generate_exploit(ctx: TaskContext, cfg: Config) -> TaskContext:
    """
    Full exploit pipeline integrated with the orchestrator context.

    Steps:
        1. Plan the exploit from root cause analysis
        2. Generate exploit C code
        3. Stitch / finalize code
        4. Compile for target architecture
        5. Verify privilege escalation on target (if SSH configured)
    """
    if not ctx.root_cause:
        ctx.errors.append("Cannot generate exploit: no root cause analysis")
        return ctx

    work_dir = ctx.work_dir or Path.cwd() / "syzploit_output"
    work_dir.mkdir(parents=True, exist_ok=True)

    arch = ctx.target_arch or Arch.ARM64
    platform = ctx.target_platform or Platform.ANDROID
    arch_str = arch.value if isinstance(arch, Arch) else str(arch)

    # Step 1: Plan
    console.print("  [bold]Planning exploit…[/]")
    plan = plan_exploit(
        ctx.root_cause,
        target_kernel=ctx.target_kernel,
        arch=arch,
        platform=platform,
        cfg=cfg,
    )

    # Attach PoC source if available
    if ctx.crash_report and ctx.crash_report.reproducer_c:
        plan.poc_source = ctx.crash_report.reproducer_c

    ctx.exploit_plan = plan
    ctx.log("exploit", "plan", f"technique={plan.technique}, {len(plan.steps)} steps")

    # Step 1b: Resolve kernel offsets (if vmlinux / kallsyms available)
    kernel_offsets_header = ""
    try:
        from .kernel_resolver import resolve_kernel_offsets as _resolve_offsets

        vmlinux = getattr(cfg, "vmlinux_path", None)
        target_info = ctx.target_system_info
        if vmlinux or (target_info and target_info.kallsyms_path):
            console.print("  [bold]Resolving kernel offsets…[/]")
            _resolver, kernel_offsets_header = _resolve_offsets(
                target_info=target_info,
                vmlinux_path=vmlinux,
                work_dir=work_dir,
            )
            if kernel_offsets_header:
                header_path = work_dir / "kernel_offsets.h"
                header_path.write_text(kernel_offsets_header)
                console.print(f"  Written kernel_offsets.h ({len(kernel_offsets_header)} bytes)")
                ctx.log("exploit", "kernel_offsets", f"resolved, {len(kernel_offsets_header)} bytes")
    except Exception as exc:
        console.print(f"  [dim]Kernel offset resolution skipped: {exc}[/]")

    # Step 1c: Gather primitive library context
    primitive_context = ""
    try:
        from .primitive_library import PrimitiveLibrary
        plib = PrimitiveLibrary()
        primitive_context = plib.format_for_prompt()
    except Exception:
        pass

    # Step 1d: Gather kernel source context
    kernel_source_context = ""
    try:
        from ..analysis.kernel_source import KernelSourceContext
        kernel_tree = getattr(cfg, "kernel_tree_path", None)
        if kernel_tree:
            ksc = KernelSourceContext(kernel_tree)
            funcs = []
            if ctx.root_cause:
                if ctx.root_cause.vulnerable_function:
                    funcs.append(ctx.root_cause.vulnerable_function)
                funcs.extend(ctx.root_cause.kernel_functions[:3])
            structs = ctx.root_cause.affected_structs if ctx.root_cause else []
            kernel_source_context = ksc.format_context_for_prompt(
                funcs, structs, max_total_lines=400
            )
    except Exception:
        pass

    # Step 1e: Format exploitation technique context from blog analysis
    exploitation_technique_context = ""
    if ctx.root_cause and ctx.root_cause.exploitation_details:
        exploitation_technique_context = _format_exploitation_details(
            ctx.root_cause.exploitation_details
        )

    # Step 1f: Find and load reference exploit if available
    reference_exploit_context = ""
    try:
        reference_exploit_context = _find_reference_exploit(ctx)
    except Exception:
        pass

    # Step 2: Generate code
    console.print("  [bold]Generating exploit code…[/]")

    # Gather structured feedback from previous exploit verification attempts
    previous_feedback = ""
    previous_source = ""
    exploit_attempts = ctx.exploit_verification_attempts()
    if exploit_attempts:
        previous_feedback = _build_structured_feedback(exploit_attempts[-1])
    if ctx.exploit_result and ctx.exploit_result.source_code:
        previous_source = ctx.exploit_result.source_code

    # Extract CVE ID for validator
    target_cve = ""
    if ctx.root_cause:
        m = re.search(r"(CVE-\d{4}-\d+)", ctx.root_cause.summary or "", re.IGNORECASE)
        if m:
            target_cve = m.group(1)
        if not target_cve and hasattr(ctx, "input_value"):
            m = re.search(r"(CVE-\d{4}-\d+)", str(getattr(ctx, "input_value", "")), re.IGNORECASE)
            if m:
                target_cve = m.group(1)

    raw_code = generate_exploit_code(
        plan,
        root_cause=ctx.root_cause,
        previous_feedback=previous_feedback,
        previous_source=previous_source,
        kernel_offsets_header=kernel_offsets_header,
        primitive_context=primitive_context,
        kernel_source_context=kernel_source_context,
        gdb_trace_context=ctx.format_gdb_trace_context(),
        exploitation_technique_context=exploitation_technique_context,
        reference_exploit_context=reference_exploit_context,
        cfg=cfg,
    )

    # Step 2b: Validate generated code quality (rule-based)
    console.print("  [bold]Validating generated code…[/]")
    validation = validate_exploit_code(
        raw_code,
        target_cve=target_cve,
        target_slab=plan.slab_cache,
    )

    # Step 2c: LLM review (catches semantic issues the validator can't)
    llm_review = {"ready": True, "critical_issues": [], "stub_functions": [], "suggestions": []}
    if not validation.has_errors:
        # Only run LLM review if rule-based validation passed
        console.print("  [bold]Running pre-compilation LLM review…[/]")
        llm_review = review_exploit_code(
            raw_code,
            target_cve=target_cve,
            vuln_type=plan.vulnerability_type.value,
            target_struct=plan.target_struct,
            slab_cache=plan.slab_cache,
            cfg=cfg,
        )
        if not llm_review["ready"]:
            console.print(
                f"  [yellow]LLM review flagged {len(llm_review['critical_issues'])} "
                f"critical issues[/]"
            )

    # Step 2d: Regenerate once if validation or review found critical issues
    needs_regen = validation.has_errors or (
        not llm_review["ready"] and llm_review.get("critical_issues")
    )
    if needs_regen:
        console.print("  [yellow]Code quality issues detected — regenerating…[/]")
        regen_feedback_parts = []

        # Add rule-based validation feedback
        if validation.has_errors:
            regen_feedback_parts.append(validation.format_for_llm())

        # Add LLM review feedback
        if not llm_review["ready"]:
            regen_feedback_parts.append(
                "=== LLM CODE REVIEW ISSUES ===\n"
                + "\n".join(f"  - {issue}" for issue in llm_review["critical_issues"])
            )
            if llm_review.get("stub_functions"):
                regen_feedback_parts.append(
                    "Stub functions that need real implementation: "
                    + ", ".join(llm_review["stub_functions"])
                )
            if llm_review.get("suggestions"):
                regen_feedback_parts.append(
                    "Suggested fixes:\n"
                    + "\n".join(f"  - {s}" for s in llm_review["suggestions"])
                )

        regen_feedback = "\n\n".join(regen_feedback_parts)

        # Combine with any existing feedback
        combined_feedback = previous_feedback
        if combined_feedback:
            combined_feedback += "\n\n" + regen_feedback
        else:
            combined_feedback = regen_feedback

        raw_code = generate_exploit_code(
            plan,
            root_cause=ctx.root_cause,
            previous_feedback=combined_feedback,
            previous_source=raw_code,  # Pass the rejected code
            kernel_offsets_header=kernel_offsets_header,
            primitive_context=primitive_context,
            kernel_source_context=kernel_source_context,
            gdb_trace_context=ctx.format_gdb_trace_context(),
            exploitation_technique_context=exploitation_technique_context,
            reference_exploit_context=reference_exploit_context,
            cfg=cfg,
        )

        # Re-validate the regenerated code (log only, don't loop)
        validation2 = validate_exploit_code(
            raw_code, target_cve=target_cve, target_slab=plan.slab_cache,
        )
        if validation2.has_errors:
            console.print(
                f"  [yellow]Regenerated code still has {validation2.error_count} "
                f"errors — proceeding anyway[/]"
            )

    # Step 3: Stitch — inject post-exploit code
    post_exploit_code = ""
    try:
        from .post_exploit import PostExploitGenerator
        peg = PostExploitGenerator(
            platform=platform.value if isinstance(platform, Platform) else str(platform)
        )
        post_exploit_code = peg.generate_post_exploit_payload()
    except Exception:
        pass

    code = stitch_exploit(
        plan, raw_code,
        kernel_offsets_header=kernel_offsets_header,
        post_exploit_code=post_exploit_code,
        cfg=cfg,
    )

    # Step 4: Write and compile
    source_path = work_dir / "exploit.c"
    source_path.write_text(code)
    console.print(f"  Written to {source_path}")

    binary_path = work_dir / "exploit"
    console.print(f"  [bold]Compiling for {arch_str}…[/]")

    # Use multi-file compiler if we have extra headers
    if kernel_offsets_header:
        from .exploit_compiler import ExploitCompiler
        ec = ExploitCompiler(arch=arch_str, cfg=cfg)
        success, error = ec.compile_exploit(
            str(source_path),
            str(binary_path),
            header_files={"kernel_offsets.h": kernel_offsets_header},
        )
    else:
        success, error = compile_reproducer(
            str(source_path),
            str(binary_path),
            arch=arch_str,
            cfg=cfg,
        )

    result = ExploitResult(
        success=success,
        plan=plan,
        source_code=code,
        source_path=str(source_path),
        binary_path=str(binary_path) if success else None,
        target_kernel=ctx.target_kernel,
        arch=arch,
    )

    if not success:
        result.notes.append(f"Compilation failed: {error[:500]}")
        console.print(f"  [red]Compilation failed: {error[:200]}[/]")
    else:
        console.print(f"  [green]Exploit compiled: {binary_path}[/]")

    ctx.exploit_result = result

    # Step 5: Verify on target (if SSH is configured)
    if success and ctx.ssh_host:
        console.print("  [bold]Verifying exploit on target…[/]")
        ctx = _verify_exploit_step(ctx, cfg, str(binary_path))

    return ctx


def _verify_exploit_step(ctx: TaskContext, cfg: Config, binary_path: str) -> TaskContext:
    """Run exploit verification and record the attempt."""
    from ..infra.verification import verify_exploit

    attempt_num = len(ctx.exploit_verification_attempts()) + 1
    use_adb = ctx.target_platform.value == "android" and ctx.instance is not None

    # Build GDB monitor function list: defaults + vulnerable functions
    monitor_funcs = [
        "commit_creds", "prepare_kernel_cred", "override_creds",
        "revert_creds", "copy_creds", "sel_write_enforce",
        "selinux_state", "__sys_setresuid", "__sys_setresgid",
    ]
    if ctx.root_cause:
        if ctx.root_cause.vulnerable_function:
            monitor_funcs.append(ctx.root_cause.vulnerable_function)
        for fn in (ctx.root_cause.kernel_functions or [])[:5]:
            if fn not in monitor_funcs:
                monitor_funcs.append(fn)

    vresult = verify_exploit(
        binary_path,
        ssh_host=ctx.ssh_host,
        ssh_port=ctx.ssh_port,
        ssh_user=getattr(cfg, "ssh_user", "root"),
        ssh_key=getattr(cfg, "ssh_key", None),
        instance=ctx.instance,
        start_cmd=ctx.start_cmd,
        stop_cmd=ctx.stop_cmd,
        exploit_start_cmd=ctx.exploit_start_cmd,
        gdb_port=ctx.gdb_port,
        setup_tunnels=ctx.setup_tunnels,
        persistent=ctx.persistent,
        use_adb=use_adb,
        vmlinux_path=getattr(cfg, "vmlinux_path", None),
        kallsyms_path=getattr(ctx, "kallsyms_path", None),
        arch=ctx.target_arch.value if hasattr(ctx, "target_arch") and ctx.target_arch else "arm64",
        monitor_functions=monitor_funcs,
    )

    attempt = VerificationAttempt(
        attempt_number=attempt_num,
        target="exploit",
        binary_path=binary_path,
        success=vresult["success"],
        uid_before=vresult.get("uid_before"),
        uid_after=vresult.get("uid_after"),
        privilege_escalated=vresult.get("privilege_escalated", False),
        crash_occurred=vresult.get("crash_occurred", False),
        crash_pattern=vresult.get("crash_pattern", ""),
        device_stable=vresult.get("device_stable", True),
        failure_reason=vresult.get("failure_reason", ""),
        feedback=vresult.get("feedback", ""),
        exploit_output=vresult.get("exploit_output", "")[:3000],
        dmesg_new=vresult.get("dmesg_new", "")[:3000],
        gdb_functions_hit=vresult.get("gdb_functions_hit", []),
        gdb_functions_missed=vresult.get("gdb_functions_missed", []),
        gdb_crash_info=vresult.get("gdb_crash_info"),
    )
    ctx.verification_history.append(attempt)

    # Accumulate GDB trace results for exploit generator prompt
    if vresult.get("gdb_functions_hit") or vresult.get("gdb_functions_missed"):
        ctx.gdb_trace_results.append({
            "target": "exploit",
            "attempt": attempt_num,
            "functions_hit": vresult.get("gdb_functions_hit", []),
            "functions_missed": vresult.get("gdb_functions_missed", []),
            "crash_info": vresult.get("gdb_crash_info"),
        })

    if vresult["success"] and ctx.exploit_result:
        ctx.exploit_result.privilege_escalation_confirmed = True
        ctx.exploit_result.uid_before = vresult.get("uid_before")
        ctx.exploit_result.uid_after = vresult.get("uid_after")
        ctx.exploit_result.verification_log = vresult.get("exploit_output", "")
        console.print("  [bold green]✓ Exploit verified — privilege escalation confirmed![/]")
    elif ctx.exploit_result:
        ctx.exploit_result.notes.append(
            f"Verification failed: {vresult.get('failure_reason', 'unknown')}"
        )
        console.print(
            f"  [bold yellow]Verification failed: "
            f"{vresult.get('failure_reason', 'unknown')}[/]"
        )

    return ctx
