"""
infra.gdb — GDB integration for kernel debugging and tracing.

Provides GDB attachment, breakpoint management, and kernel tracing
helpers used by dynamic analysis and feasibility checking.

The approach mirrors syzploit_old's proven method:
  1. Resolve function names → addresses using kallsyms (avoiding the need
     for a local vmlinux with debug symbols).
  2. Generate a GDB Python script that sets breakpoints at raw addresses,
     auto-continues on each hit, and exports an events JSON.
  3. Generate a GDB commands file that loads vmlinux (if available) or
     sets architecture, connects to the remote stub, sources the Python
     script, and runs ``continue``.
  4. Run ``gdb-multiarch -batch -nx -x commands.txt`` as a subprocess.
  5. Parse the JSON events file to determine which functions were hit.
"""

from __future__ import annotations

import json
import os
import re
import shutil
import signal
import subprocess
import tempfile
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from ..core.log import console


# ── Kallsyms helpers ──────────────────────────────────────────────────

def _resolve_functions_from_kallsyms(
    functions: List[str],
    kallsyms_path: Optional[str],
) -> Dict[str, int]:
    """Resolve kernel function names to addresses using a kallsyms file.

    Returns ``{function_name: address}`` for functions found.
    Skips entries with zero addresses (kptr_restrict still active).
    """
    if not kallsyms_path or not Path(kallsyms_path).is_file():
        return {}

    name_to_addr: Dict[str, int] = {}
    wanted = set(functions)
    try:
        with open(kallsyms_path) as f:
            for line in f:
                parts = line.strip().split(None, 2)
                if len(parts) < 3:
                    continue
                addr_str, sym_type, sym_name = parts[0], parts[1], parts[2]
                # Some kallsyms lines have a module suffix like "[binder_linux]"
                sym_name = sym_name.split()[0]
                if sym_name in wanted:
                    addr = int(addr_str, 16)
                    if addr != 0:
                        name_to_addr[sym_name] = addr
    except Exception:
        pass
    return name_to_addr


# ── GDB script generation ────────────────────────────────────────────

def _generate_gdb_python_script(
    function_addrs: Dict[str, int],
    events_file: str,
    arch: str = "arm64",
) -> str:
    """Generate a GDB Python script that sets breakpoints and auto-continues.

    This script is ``source``d by GDB.  It uses the ``gdb`` Python API
    (available inside GDB's embedded Python interpreter) to:
    - Set hardware breakpoints at resolved kernel addresses using custom
      Breakpoint subclasses whose ``stop()`` records the hit and returns
      ``False`` (telling GDB to auto-resume without entering interactive
      mode).  This is the proven approach from syzploit_old.
    - Export results as JSON to *events_file* via atexit, on-exit event,
      and periodic saves (triple redundancy).

    Based on the proven approach from syzploit_old's ``gdb.py`` which
    uses ``gdb.Breakpoint`` subclasses with ``stop()`` returning False.
    """
    bp_entries = json.dumps(
        {name: hex(addr) for name, addr in function_addrs.items()}
    )

    return f'''# Auto-generated GDB Python script for kernel path verification
# Generated by syzploit — do not edit
#
# Uses hardware breakpoints (preferred) via gdb.BP_HARDWARE_BREAKPOINT,
# falling back to software breakpoints if HW BPs aren't supported.
# Mirrors syzploit_old's proven approach: custom Breakpoint subclasses
# with stop() returning False for zero-overhead auto-continue.
import gdb
import json
import time
import atexit

_events_file = "{events_file}"
_bp_map = {bp_entries}  # name -> hex_addr
_hits = {{}}  # name -> hit_count
_start_time = time.time()
_last_export = time.time()
_EXPORT_INTERVAL = 15  # seconds between periodic exports
_BP_THROTTLE_MAX = 200  # auto-disable BP after this many hits

# Allow pending breakpoints (defers resolution if needed)
gdb.execute("set breakpoint pending on", to_string=True)


# ── Results export (triple redundancy: atexit + on-exit + periodic) ──

def _save_results():
    """Export hit results as JSON."""
    try:
        data = {{
            "functions_hit": {{k: v for k, v in _hits.items() if v > 0}},
            "functions_missed": [
                k for k in _bp_map if _hits.get(k, 0) == 0
            ],
            "total_hits": sum(_hits.values()),
            "elapsed": time.time() - _start_time,
        }}
        with open(_events_file, "w") as f:
            json.dump(data, f, indent=2)
        gdb.write(
            f"[SYZPLOIT] Results saved: {{len(data['functions_hit'])}} "
            f"function(s) hit, {{data['total_hits']}} total hits\\n"
        )
    except Exception as e:
        gdb.write(f"[SYZPLOIT] Failed to save results: {{e}}\\n")

atexit.register(_save_results)

# Also save on inferior exit
def _on_exit(event):
    gdb.write("[SYZPLOIT] Inferior exited, saving results...\\n")
    _save_results()

try:
    gdb.events.exited.connect(_on_exit)
except Exception:
    pass  # Some GDB versions don't support this


# ── Custom Breakpoint class (mirrors syzploit_old's FuncBreakpoint) ──
#
# The key insight from syzploit_old: Breakpoint.stop() returning False
# tells GDB to auto-resume without ever entering interactive mode.
# This is far more reliable than gdb.events.stop + gdb.execute("continue")
# because:
#   1. No re-entrant continue calls
#   2. Events are recorded synchronously before resume
#   3. GDB stays in its normal continue flow

class SyzploitBreakpoint(gdb.Breakpoint):
    """Breakpoint that records hits and auto-continues (HW preferred)."""

    def __init__(self, spec, func_name):
        # Prefer hardware breakpoints for kernel debugging via QEMU stub.
        # Fall back to software BP if HW BPs aren't supported or limit
        # is exceeded.
        try:
            super().__init__(spec, gdb.BP_HARDWARE_BREAKPOINT)
        except (ValueError, RuntimeError, gdb.error):
            super().__init__(spec, gdb.BP_BREAKPOINT)
        self.func_name = func_name
        self.silent = True  # Suppress default GDB output
        gdb.write(f"[SYZPLOIT] BP set: {{func_name}} at {{spec}} (BP#{{self.number}})\\n")

    def stop(self):
        """Called when this breakpoint is hit.

        Records the event and returns False to auto-continue.
        Returning False means GDB never pauses — it just records and
        resumes, which is exactly what syzploit_old does.
        """
        global _last_export
        count = _hits.get(self.func_name, 0) + 1
        _hits[self.func_name] = count
        elapsed = time.time() - _start_time
        gdb.write(
            f"[SYZPLOIT] HIT: {{self.func_name}} "
            f"(count={{count}}, t={{elapsed:.1f}}s)\\n"
        )

        # Auto-throttle: disable BP after too many hits to avoid
        # overwhelming GDB (same design as syzploit_old)
        if count >= _BP_THROTTLE_MAX:
            gdb.write(
                f"[SYZPLOIT] Throttle: disabling {{self.func_name}} "
                f"after {{count}} hits\\n"
            )
            self.enabled = False

        # Periodic export (in case GDB crashes or gets killed)
        now = time.time()
        if now - _last_export >= _EXPORT_INTERVAL:
            _save_results()
            _last_export = now

        return False  # Auto-continue (DO NOT return True)


# ── Install breakpoints ──────────────────────────────────────────────
#
# We use the GDB Python API Breakpoint class directly.  Setting
# spec="*0xaddr" creates a breakpoint at a raw address.  By default
# GDB uses software breakpoints; for kernel addresses via QEMU stub
# we need hardware breakpoints.  We first try setting as HW via
# gdb.execute("hbreak"), then fall back to the class-based approach.

_installed_bps = {{}}  # name -> SyzploitBreakpoint
gdb.write(f"[SYZPLOIT] Installing {{len(_bp_map)}} breakpoint(s)...\\n")

for _name, _addr_hex in _bp_map.items():
    try:
        _bp = SyzploitBreakpoint(f"*{{_addr_hex}}", _name)
        _installed_bps[_name] = _bp
    except gdb.error as _e:
        gdb.write(f"[SYZPLOIT] BP failed for {{_name}} at {{_addr_hex}}: {{_e}}\\n")

gdb.write(f"[SYZPLOIT] {{len(_installed_bps)}} breakpoint(s) installed, kernel will continue\\n")

# Save initial state before continue (in case of early crash)
_save_results()
'''


def _generate_gdb_commands_file(
    gdb_host: str,
    gdb_port: int,
    script_path: str,
    vmlinux_path: Optional[str] = None,
    arch: str = "arm64",
    log_file: Optional[str] = None,
) -> str:
    """Generate a GDB commands file for batch-mode execution.

    The commands:
    1. Set architecture (if no vmlinux)
    2. Load vmlinux with ``file`` (if available — gives symbol names)
    3. Connect to the remote GDB stub
    4. Source the Python monitoring script
    5. ``continue`` (the script's breakpoints fire and auto-continue)
    6. On exit, disconnect and quit
    """
    lines: list[str] = []

    # Architecture hint when there's no vmlinux to auto-detect
    if arch in ("arm64", "aarch64"):
        lines.append("set architecture aarch64")
    elif arch in ("x86_64", "x86"):
        lines.append("set architecture i386:x86-64")

    # Load vmlinux if available (gives symbols for nicer output)
    if vmlinux_path and Path(vmlinux_path).is_file():
        lines.append(f"file {vmlinux_path}")

    # Pagination and confirmation off for batch mode
    lines.append("set pagination off")
    lines.append("set confirm off")
    lines.append("set tcp connect-timeout 30")

    # Logging
    if log_file:
        lines.append(f"set logging file {log_file}")
        lines.append("set logging overwrite on")
        lines.append("set logging enabled on")

    # Connect to the kernel GDB stub
    lines.append(f"target remote {gdb_host}:{gdb_port}")

    # Source the Python instrumentation script
    lines.append(f"source {script_path}")

    # Continue — the Python script's custom breakpoint classes handle
    # auto-continue by returning False from stop().  GDB stays in the
    # continue state until interrupted (SIGINT from stop_monitoring)
    # or the remote disconnects (VM shutdown/crash).
    # We use a Python loop (like syzploit_old's syz_safe_continue) for
    # error recovery — if the connection drops and reconnects, or if
    # GDB gets interrupted, the loop retries continue.
    lines.append("python")
    lines.append("import time")
    lines.append("_stop_count = 0")
    lines.append("_max_stops = 100000")
    lines.append("while _stop_count < _max_stops:")
    lines.append("    try:")
    lines.append('        gdb.execute("continue")')
    lines.append("        _stop_count += 1")
    lines.append("    except gdb.error as e:")
    lines.append('        err = str(e).lower()')
    lines.append("        if 'not running' in err or 'not being run' in err:")
    lines.append("            time.sleep(1)")
    lines.append("            continue")
    lines.append("        if 'connection closed' in err or 'remote' in err:")
    lines.append('            gdb.write(f"[SYZPLOIT] Connection lost: {e}\\n")')
    lines.append("            break")
    lines.append('        gdb.write(f"[SYZPLOIT] Continue error: {e}\\n")')
    lines.append("        break")
    lines.append("    except KeyboardInterrupt:")
    lines.append("        break")
    lines.append("end")

    # Graceful exit
    lines.append("disconnect")
    lines.append("quit")

    return "\n".join(lines) + "\n"


# ── GDB binary detection ─────────────────────────────────────────────

def _find_gdb_binary(arch: str = "arm64") -> str:
    """Find an appropriate GDB binary for the target architecture."""
    if arch in ("arm64", "aarch64"):
        candidates = ["gdb-multiarch", "aarch64-linux-gnu-gdb", "gdb"]
    else:
        candidates = ["gdb", "gdb-multiarch"]

    for name in candidates:
        if shutil.which(name):
            return name

    return "gdb-multiarch"  # fallback; will error if not installed


# ── Main controller ───────────────────────────────────────────────────

class GDBController:
    """
    Control GDB via subprocess for kernel path verification.

    The design mirrors syzploit_old's approach:
    - Generate a GDB Python script with breakpoints
    - Run GDB in batch mode as a background subprocess
    - Parse the exported JSON events file after stopping

    Unlike the previous approach, this works WITHOUT vmlinux by
    resolving function names to addresses via kallsyms BEFORE
    starting GDB.
    """

    def __init__(
        self,
        gdb_binary: Optional[str] = None,
        vmlinux: Optional[str] = None,
        arch: str = "arm64",
    ) -> None:
        self.gdb_binary = gdb_binary or _find_gdb_binary(arch)
        self.vmlinux = vmlinux
        self.arch = arch
        self._process: Optional[subprocess.Popen] = None
        self._work_dir: Optional[str] = None
        self._events_file: Optional[str] = None
        self._function_names: List[str] = []

    def attach(self, host: str = "localhost", port: int = 1234) -> bool:
        """Quick connectivity check — attach and immediately detach."""
        cmd = [self.gdb_binary]
        if self.vmlinux and Path(self.vmlinux).is_file():
            cmd.append(self.vmlinux)
        cmd += [
            "-ex", f"target remote {host}:{port}",
            "-ex", "set pagination off",
            "-batch",
        ]
        try:
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=30
            )
            return result.returncode == 0
        except Exception:
            return False

    # ── Background monitoring ─────────────────────────────────────────

    def start_monitoring(
        self,
        functions: List[str],
        *,
        host: str = "localhost",
        port: int = 1234,
        kallsyms_path: Optional[str] = None,
    ) -> bool:
        """Start GDB as a background process monitoring kernel breakpoints.

        1. Resolve *functions* → addresses using *kallsyms_path*.
        2. Generate a GDB Python script with auto-continue breakpoints.
        3. Generate a GDB commands file.
        4. Launch ``gdb-multiarch -batch -nx -x commands.txt`` in the
           background.

        The kernel keeps running — breakpoints fire and GDB auto-continues.
        Call :meth:`stop_monitoring` after the reproducer finishes to
        read the results.

        Returns True if GDB was started successfully.
        """
        if self._process is not None:
            console.print("  [yellow]GDB monitor already running[/]")
            return True

        self._function_names = list(functions)

        # ── Resolve function names → addresses ────────────────────────
        resolved = _resolve_functions_from_kallsyms(functions, kallsyms_path)
        if not resolved:
            # Try using function names directly (works if vmlinux is loaded)
            if self.vmlinux and Path(self.vmlinux).is_file():
                console.print(
                    "  [dim]No kallsyms addresses — will use vmlinux "
                    "symbol names for breakpoints[/]"
                )
                # Use name-based breakpoints (GDB resolves via vmlinux)
                resolved = {fn: 0 for fn in functions}
            else:
                console.print(
                    "  [yellow]Cannot set breakpoints: no kallsyms "
                    "addresses and no vmlinux for symbol resolution[/]"
                )
                return False

        found_names = [n for n in functions if n in resolved]
        missed_names = [n for n in functions if n not in resolved]
        if missed_names:
            console.print(
                f"  [dim]Resolved {len(found_names)}/{len(functions)} "
                f"functions. Missing: {missed_names}[/]"
            )

        # Only use entries with actual addresses (skip the 0-address
        # placeholder for name-based breakpoints handled differently)
        addr_map = {n: a for n, a in resolved.items() if a != 0}
        name_only = [n for n, a in resolved.items() if a == 0]

        # ── Create working directory for temp files ───────────────────
        self._work_dir = tempfile.mkdtemp(prefix="syzploit_gdb_")
        self._events_file = os.path.join(self._work_dir, "events.json")
        script_path = os.path.join(self._work_dir, "monitor.py")
        commands_path = os.path.join(self._work_dir, "commands.gdb")
        log_path = os.path.join(self._work_dir, "gdb_output.log")

        # ── Generate the Python script ────────────────────────────────
        # For functions with addresses, use *0xaddr breakpoints
        # For name-only functions, the script will use name-based breakpoints
        all_bp_map: Dict[str, int] = dict(addr_map)
        # Name-only breakpoints get a special marker address of 0
        # and we'll handle them in the script template
        script_content = _generate_gdb_python_script(
            all_bp_map, self._events_file, self.arch,
        )

        # If there are name-only functions (vmlinux available), append
        # name-based breakpoint setup to the script using SyzploitBreakpoint
        if name_only:
            extra = "\n# Name-based breakpoints (resolved via vmlinux)\n"
            for fn in name_only:
                extra += f'''
try:
    _bp = SyzploitBreakpoint("{fn}", "{fn}")
    _installed_bps["{fn}"] = _bp
    gdb.write("[SYZPLOIT] Name BP set: {fn}\\n")
except Exception as _e:
    gdb.write(f"[SYZPLOIT] Name BP failed: {fn}: {{_e}}\\n")
'''
            script_content += extra

        with open(script_path, "w") as f:
            f.write(script_content)

        # ── Generate the commands file ────────────────────────────────
        commands_content = _generate_gdb_commands_file(
            gdb_host=host,
            gdb_port=port,
            script_path=script_path,
            vmlinux_path=self.vmlinux,
            arch=self.arch,
            log_file=log_path,
        )
        with open(commands_path, "w") as f:
            f.write(commands_content)

        # ── Launch GDB ────────────────────────────────────────────────
        # NOTE: Do NOT use -batch.  In batch mode GDB may exit after
        # the first auto-continue breakpoint cycle.  syzploit_old used
        # `gdb -q` (no -batch) so GDB stays alive, blocking on the
        # `continue` command until we SIGINT it from stop_monitoring().
        console.print(
            f"  [dim]GDB command: {self.gdb_binary} -q -nx "
            f"-x {commands_path}[/]"
        )
        try:
            self._process = subprocess.Popen(
                [self.gdb_binary, "-q", "-nx", "-x", commands_path],
                stdin=subprocess.DEVNULL,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
            )
            # Give GDB time to connect, load script, set breakpoints
            time.sleep(5)
            if self._process.poll() is not None:
                # GDB exited already
                out = self._process.stdout.read().decode(errors="replace") if self._process.stdout else ""
                console.print(
                    f"  [yellow]GDB exited early "
                    f"(rc={self._process.returncode}): "
                    f"{out[:2000]}[/]"
                )
                self._process = None
                return False
            console.print(
                f"  [dim]GDB monitor started with {len(resolved)} "
                f"breakpoint(s) ({len(addr_map)} by address, "
                f"{len(name_only)} by name)[/]"
            )
            return True
        except FileNotFoundError:
            console.print(
                f"  [red]GDB binary not found: {self.gdb_binary}. "
                f"Install gdb-multiarch.[/]"
            )
            self._process = None
            return False
        except Exception as exc:
            console.print(f"  [yellow]GDB monitor start failed: {exc}[/]")
            self._process = None
            return False

    def stop_monitoring(self) -> Dict[str, bool]:
        """Stop GDB and return ``{function_name: was_hit}`` from the events file.

        Sends SIGINT to interrupt GDB's ``continue`` loop, waits for it to
        run the atexit handler that writes the events JSON, then parses
        the file.

        The GDB script uses custom Breakpoint subclasses that also write
        periodic exports, so even if atexit doesn't fire, we should have
        partial results from the last periodic save.
        """
        if self._process is None:
            return {}

        gdb_stdout = ""

        try:
            # Send SIGINT to interrupt the Python continue loop inside GDB.
            # This causes the KeyboardInterrupt handler to break the loop,
            # then GDB runs atexit handlers (which call _save_results).
            self._process.send_signal(signal.SIGINT)
            time.sleep(3)  # Give atexit handler time to write JSON

            # Send another SIGINT in case the first was caught by GDB itself
            # and not forwarded to the Python script
            try:
                if self._process.poll() is None:
                    self._process.send_signal(signal.SIGINT)
                    time.sleep(2)
            except Exception:
                pass

            # Now terminate
            if self._process.poll() is None:
                self._process.terminate()
            try:
                out_bytes, _ = self._process.communicate(timeout=15)
                gdb_stdout = out_bytes.decode(errors="replace") if out_bytes else ""
            except subprocess.TimeoutExpired:
                self._process.kill()
                out_bytes, _ = self._process.communicate(timeout=5)
                gdb_stdout = out_bytes.decode(errors="replace") if out_bytes else ""
        except Exception as exc:
            console.print(f"  [yellow]GDB monitor stop error: {exc}[/]")
            try:
                self._process.kill()
                out_bytes, _ = self._process.communicate(timeout=5)
                gdb_stdout = out_bytes.decode(errors="replace") if out_bytes else ""
            except Exception:
                pass

        self._process = None

        # Log GDB output for debugging
        if gdb_stdout:
            console.print(
                f"  [dim]GDB output ({len(gdb_stdout)} bytes): "
                f"{gdb_stdout[:400]}[/]"
            )

        # ── Parse the events JSON file ────────────────────────────────
        hits: Dict[str, bool] = {fn: False for fn in self._function_names}

        if self._events_file and Path(self._events_file).is_file():
            try:
                with open(self._events_file) as f:
                    data = json.load(f)
                funcs_hit = data.get("functions_hit", {})
                for fn in self._function_names:
                    if fn in funcs_hit and funcs_hit[fn] > 0:
                        hits[fn] = True
                console.print(
                    f"  [dim]Events file: {len(funcs_hit)} function(s) hit, "
                    f"{data.get('total_hits', 0)} total[/]"
                )
            except Exception as exc:
                console.print(
                    f"  [yellow]Could not parse events file: {exc}[/]"
                )
        else:
            # Fallback: parse GDB stdout for "[SYZPLOIT] HIT:" lines
            console.print(
                "  [dim]No events file — parsing GDB stdout for hits[/]"
            )
            for line in gdb_stdout.splitlines():
                m = re.search(r"\[SYZPLOIT\] HIT: (\S+)", line)
                if m:
                    fn_name = m.group(1)
                    if fn_name in hits:
                        hits[fn_name] = True

        # Clean up temp files
        if self._work_dir:
            try:
                import shutil as _shutil
                _shutil.rmtree(self._work_dir, ignore_errors=True)
            except Exception:
                pass
            self._work_dir = None

        return hits

    # ── Legacy / simple methods ───────────────────────────────────────

    def set_breakpoints_and_run(
        self,
        functions: List[str],
        *,
        host: str = "localhost",
        port: int = 1234,
        timeout: int = 60,
        kallsyms_path: Optional[str] = None,
    ) -> Dict[str, bool]:
        """One-shot: set breakpoints, continue, collect results.

        Blocking call that runs for *timeout* seconds.
        """
        ok = self.start_monitoring(
            functions, host=host, port=port,
            kallsyms_path=kallsyms_path,
        )
        if not ok:
            return {fn: False for fn in functions}

        # Let GDB run for the timeout duration
        time.sleep(timeout)

        return self.stop_monitoring()

    def run_gdb_script(
        self,
        script_path: str,
        *,
        host: str = "localhost",
        port: int = 1234,
        timeout: int = 120,
    ) -> Tuple[int, str]:
        """Execute a GDB Python script against a remote target."""
        cmd = [self.gdb_binary]
        if self.vmlinux and Path(self.vmlinux).is_file():
            cmd.append(self.vmlinux)
        cmd += [
            "-ex", f"target remote {host}:{port}",
            "-x", script_path,
            "-batch",
        ]
        try:
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=timeout
            )
            return result.returncode, result.stdout + result.stderr
        except subprocess.TimeoutExpired:
            return -1, "GDB script timed out"
        except Exception as exc:
            return -1, str(exc)

    # ── Crash-site analysis ───────────────────────────────────────────

    def capture_crash_state(
        self,
        *,
        host: str = "localhost",
        port: int = 1234,
    ) -> Dict[str, Any]:
        """Connect to a halted kernel and capture diagnostic state.

        After an exploit causes a kernel panic/OOPS, the QEMU GDB stub
        halts the CPU.  This method connects, captures registers and
        backtrace, then disconnects.  Returns a dict with:
          - registers: dict of register name → hex value
          - backtrace: formatted backtrace string
          - crash_function: function name at crash site (if vmlinux loaded)
          - crash_address: program counter value
          - stack_dump: raw stack bytes (hex)
        """
        result: Dict[str, Any] = {
            "registers": {},
            "backtrace": "",
            "crash_function": "",
            "crash_address": "",
            "stack_dump": "",
        }

        # Build a GDB commands file that captures state
        work_dir = tempfile.mkdtemp(prefix="syzploit_gdb_crash_")
        state_file = os.path.join(work_dir, "crash_state.json")
        script_path = os.path.join(work_dir, "crash_capture.py")
        commands_path = os.path.join(work_dir, "commands.gdb")

        capture_script = f'''# Crash state capture script — generated by syzploit
import gdb
import json

state = {{"registers": {{}}, "backtrace": "", "crash_function": "", "crash_address": "", "stack_dump": ""}}

try:
    # Capture registers
    reg_output = gdb.execute("info registers", to_string=True)
    state["registers_raw"] = reg_output
    for line in reg_output.strip().splitlines():
        parts = line.split()
        if len(parts) >= 2:
            state["registers"][parts[0]] = parts[1]

    # Get program counter
    try:
        pc = gdb.execute("print/x $pc", to_string=True)
        state["crash_address"] = pc.strip().split("=")[-1].strip() if "=" in pc else pc.strip()
    except Exception:
        pass

    # Capture backtrace
    try:
        bt = gdb.execute("bt 20", to_string=True)
        state["backtrace"] = bt
        # Extract crash function from first frame
        lines = bt.strip().splitlines()
        if lines:
            import re
            m = re.search(r"in\\s+(\\S+)", lines[0])
            if m:
                state["crash_function"] = m.group(1)
            elif "??" not in lines[0]:
                # Try extracting from format "#0 function_name ..."
                m2 = re.search(r"#0\\s+(?:0x[0-9a-f]+\\s+in\\s+)?(\\S+)", lines[0])
                if m2:
                    state["crash_function"] = m2.group(1)
    except Exception:
        pass

    # Stack dump (16 words around SP)
    try:
        if "$sp" in reg_output or "sp" in state["registers"]:
            stack = gdb.execute("x/16gx $sp", to_string=True)
            state["stack_dump"] = stack
    except Exception:
        pass

except Exception as e:
    state["error"] = str(e)

with open("{state_file}", "w") as f:
    json.dump(state, f, indent=2)

gdb.write("[SYZPLOIT] Crash state captured\\n")
'''

        with open(script_path, "w") as f:
            f.write(capture_script)

        # Build commands file
        lines: list[str] = []
        if self.arch in ("arm64", "aarch64"):
            lines.append("set architecture aarch64")
        elif self.arch in ("x86_64", "x86"):
            lines.append("set architecture i386:x86-64")
        if self.vmlinux and Path(self.vmlinux).is_file():
            lines.append(f"file {self.vmlinux}")
        lines.append("set pagination off")
        lines.append("set confirm off")
        lines.append("set tcp connect-timeout 15")
        lines.append(f"target remote {host}:{port}")
        lines.append(f"source {script_path}")
        lines.append("disconnect")
        lines.append("quit")

        with open(commands_path, "w") as f:
            f.write("\n".join(lines) + "\n")

        # Run GDB
        try:
            proc = subprocess.run(
                [self.gdb_binary, "-batch", "-nx", "-x", commands_path],
                capture_output=True, text=True, timeout=30,
            )
        except Exception as exc:
            console.print(f"  [yellow]Crash capture failed: {exc}[/]")
            return result

        # Parse results
        if Path(state_file).is_file():
            try:
                with open(state_file) as f:
                    data = json.load(f)
                result["registers"] = data.get("registers", {})
                result["backtrace"] = data.get("backtrace", "")
                result["crash_function"] = data.get("crash_function", "")
                result["crash_address"] = data.get("crash_address", "")
                result["stack_dump"] = data.get("stack_dump", "")
            except Exception:
                pass

        # Clean up
        try:
            import shutil as _shutil
            _shutil.rmtree(work_dir, ignore_errors=True)
        except Exception:
            pass

        return result
