"""
synth.py

Main orchestration module for exploit synthesis.
Combines primitives from various sources (syzanalyze, kernel-research)
and uses powerlifted planner to generate exploit plans.
"""

import json
import os
import sys
from typing import Optional, Dict, Any, List
from pathlib import Path

from .core import PrimitiveRegistry, ExploitPlan, Primitive
from .adapters.syzanalyze_adapter import load_from_analysis
from .adapters.kernelresearch_adapter import KernelResearchAdapter
from .chainreactor_integration import ChainReactor, PowerliftedSolver
from .pddl_generator import PDDLGenerator, set_debug as set_pddl_debug


def _debug(msg: str, enabled: bool = True):
    """Print debug message."""
    if enabled:
        print(f"[DEBUG:Synthesizer] {msg}", file=sys.stderr)


def _generate_capabilities_toml(primitives: List[Primitive], output_path: str, debug: bool = False) -> None:
    """
    Generate a capabilities.toml file from extracted primitives.
    
    This creates a TOML file similar to chainreactor's capabilities.toml
    but based on the primitives we've extracted from analysis.
    
    Args:
        primitives: List of Primitive objects
        output_path: Path to write the TOML file
        debug: Enable debug output
    """
    _debug(f"Generating capabilities TOML at {output_path}", debug)
    
    # Group capabilities by category
    categories: Dict[str, Dict[str, Any]] = {}
    
    for prim in primitives:
        caps = prim.provides.get('caps', [])
        if isinstance(caps, str):
            caps = [caps]
        
        for cap in caps:
            # Extract category from capability name (CAP_xxx -> xxx category)
            cap_name = cap.replace('CAP_', '')
            category = cap_name.split('_')[0] if '_' in cap_name else cap_name
            
            if category not in categories:
                categories[category] = {
                    'predicates': [],
                    'primitives': [],
                }
            
            if cap not in categories[category]['predicates']:
                categories[category]['predicates'].append(cap)
            
            prim_entry = {
                'name': prim.name,
                'description': prim.description,
                'source': prim.provides.get('source', 'unknown'),
            }
            
            # Avoid duplicates
            existing_names = [p['name'] for p in categories[category]['primitives']]
            if prim.name not in existing_names:
                categories[category]['primitives'].append(prim_entry)
    
    # Write TOML format manually (to avoid toml dependency)
    try:
        lines = [
            "# Auto-generated capabilities TOML",
            "# Generated by syzploit Synthesizer",
            "",
            "[capabilities]",
            "",
        ]
        
        for cat_name, cat_data in sorted(categories.items()):
            lines.append(f"  [{cat_name}]")
            lines.append(f"    predicates = {cat_data['predicates']}")
            lines.append("    primitives = [")
            for prim_entry in cat_data['primitives']:
                lines.append(f'      {{ name = "{prim_entry["name"]}", '
                           f'description = "{prim_entry["description"][:50]}...", '
                           f'source = "{prim_entry["source"]}" }},')
            lines.append("    ]")
            lines.append("")
        
        with open(output_path, 'w') as f:
            f.write('\n'.join(lines))
        
        _debug(f"  wrote {len(categories)} capability categories", debug)
    except Exception as e:
        _debug(f"  failed to write capabilities TOML: {e}", debug)


def synthesize(bug_id: str, goal: str, 
               kernel_research_path: Optional[str] = None,
               chainreactor_path: Optional[str] = None,
               analysis_dir: Optional[str] = None,
               vmlinux_path: Optional[str] = None,
               verbose: bool = False,
               time_limit: Optional[int] = None,
               debug: bool = False) -> Dict[str, Any]:
    """
    Orchestrate exploit synthesis by combining primitives and invoking the planner.
    
    This function:
    1. Loads primitives from syzanalyze analysis
    2. Integrates kernel-research (kernelXDK) primitives if available
    3. Generates PDDL problem file from primitives
    4. Invokes powerlifted planner to find exploit plan
    
    Args:
        bug_id: Bug identifier (e.g., syzbot hash)
        goal: Goal description (e.g., "privilege escalation to root")
        kernel_research_path: Path to kernel-research repo (optional)
        chainreactor_path: Path to chainreactor repo (for domain.pddl)
        analysis_dir: Directory containing analysis results
        vmlinux_path: Path to vmlinux for additional analysis
        verbose: Print planner output in real-time
        time_limit: Planner time limit in seconds
        debug: Enable debug output
        
    Returns:
        Dictionary with plan, PDDL files, and solver results
    """
    if debug:
        set_pddl_debug(True)
    
    _debug(f"synthesize() called", debug)
    _debug(f"  bug_id: {bug_id}", debug)
    _debug(f"  goal: {goal}", debug)
    _debug(f"  chainreactor_path: {chainreactor_path}", debug)
    _debug(f"  analysis_dir: {analysis_dir}", debug)
    
    registry = PrimitiveRegistry()

    # Resolve default submodule paths if not provided
    try:
        src_root = Path(__file__).resolve().parents[2]  # src/syzploit/Synthesizer -> src
        _debug(f"  src_root: {src_root}", debug)
        if kernel_research_path is None:
            kr_candidate = src_root / 'kernel-research'
            if kr_candidate.exists():
                kernel_research_path = str(kr_candidate)
                _debug(f"  auto-detected kernel_research_path: {kernel_research_path}", debug)
        if chainreactor_path is None:
            cr_candidate = src_root / 'chainreactor'
            if cr_candidate.exists():
                chainreactor_path = str(cr_candidate)
                _debug(f"  auto-detected chainreactor_path: {chainreactor_path}", debug)
    except Exception as e:
        _debug(f"  error detecting paths: {e}", debug)

    # Locate analysis directory
    cwd = os.getcwd()
    if not analysis_dir:
        # Try analysis_<bug_id>
        candidates = [d for d in os.listdir(cwd) if d.startswith('analysis_') and bug_id in d]
        analysis_dir = os.path.join(cwd, candidates[0]) if candidates else cwd
    _debug(f"  analysis_dir resolved to: {analysis_dir}", debug)

    # Load primitives from syzanalyze
    _debug("Loading primitives from syzanalyze...", debug)
    syz_prims = load_from_analysis(analysis_dir, registry, debug=debug)
    _debug(f"  loaded {len(syz_prims)} primitives from syzanalyze", debug)
    for p in syz_prims:
        caps = p.provides.get('caps', [])
        _debug(f"    - {p.name}: {caps}", debug)

    # Integrate kernel-research primitives
    _debug("Loading kernel-research primitives...", debug)
    kr = KernelResearchAdapter(kernel_research_path, debug=debug)
    xdk_prims = kr.list_primitives(registry, debug=debug) if kr.available() else []
    _debug(f"  loaded {len(xdk_prims)} primitives from kernel-research", debug)

    # Compose plan metadata
    target_info: Dict[str, Any] = {
        "bug_id": bug_id,
        "analysis_dir": analysis_dir,
        "vmlinux": vmlinux_path,
    }
    plan = ExploitPlan(goal=goal, target_info=target_info, primitives=registry.list())
    _debug(f"  total primitives in plan: {len(plan.primitives)}", debug)
    for p in plan.primitives:
        caps = p.provides.get('caps', p.provides.get('cap', []))
        _debug(f"    - {p.name}: {caps}", debug)

    # Generate capabilities TOML for reference
    caps_toml_path = os.path.join(analysis_dir, 'generated_capabilities.toml')
    _generate_capabilities_toml(plan.primitives, caps_toml_path, debug)

    # Simple heuristic: choose steps based on goal
    steps = []
    goal_lower = goal.lower()
    if 'priv' in goal_lower or 'root' in goal_lower or 'shell' in goal_lower:
        steps.append({"action": "generate_rop_chain", "provider": "kernelXDK"})
        steps.append({"action": "commit_creds_prepare_kernel_cred", "provider": "kernelXDK"})
    plan.steps = steps
    _debug(f"  plan steps: {steps}", debug)

    # Write spec for reference
    spec_path = os.path.join(analysis_dir, 'synth_spec.json')
    try:
        with open(spec_path, 'w') as f:
            json.dump({
                "goal": goal,
                "target": target_info,
                "primitives": [p.__dict__ for p in plan.primitives],
                "steps": plan.steps,
            }, f, indent=2)
        _debug(f"  wrote synth_spec.json to {spec_path}", debug)
    except Exception as e:
        _debug(f"  failed to write synth_spec.json: {e}", debug)

    # Initialize solver
    _debug("Initializing PowerliftedSolver...", debug)
    solver = PowerliftedSolver(debug=debug)
    
    # Check if we have chainreactor for domain.pddl
    _debug(f"Checking chainreactor path: {chainreactor_path}", debug)
    if not chainreactor_path or not Path(chainreactor_path).exists():
        _debug("chainreactor path not found!", debug)
        return {
            "plan": plan.__dict__,
            "powerlifted": {"success": False, "error": "chainreactor path not found (needed for domain.pddl)"},
            "pddl": None
        }
    
    _debug(f"Solver available: {solver.available()}", debug)
    if not solver.available():
        _debug("Powerlifted solver not available!", debug)
        return {
            "plan": plan.__dict__,
            "powerlifted": {
                "success": False, 
                "error": "Powerlifted planner not available",
                "hint": "Install powerlifted or ensure src/powerlifted exists"
            },
            "pddl": None
        }

    # Generate PDDL files
    pddl_dir = os.path.join(analysis_dir, 'pddl')
    os.makedirs(pddl_dir, exist_ok=True)
    _debug(f"PDDL output directory: {pddl_dir}", debug)
    
    _debug("Creating PDDLGenerator...", debug)
    gen = PDDLGenerator(chainreactor_path, analysis_dir=analysis_dir)
    
    # Get domain path
    _debug("Getting domain path...", debug)
    try:
        domain_src = gen.domain_path()
        _debug(f"  domain_src: {domain_src}", debug)
    except (RuntimeError, FileNotFoundError) as e:
        _debug(f"  domain path error: {e}", debug)
        return {
            "plan": plan.__dict__,
            "powerlifted": {"success": False, "error": str(e)},
            "pddl": None
        }
    
    # Generate problem PDDL
    _debug("Generating problem PDDL...", debug)
    problem_path = gen.generate_problem(
        f"{bug_id}-goal", 
        plan.primitives, 
        os.path.join(pddl_dir, 'problem.pddl'), 
        goal,
        debug=debug
    )
    _debug(f"  problem_path: {problem_path}", debug)
    
    # Copy domain to analysis dir for convenience
    try:
        import shutil
        domain_path = os.path.join(pddl_dir, 'domain.pddl')
        shutil.copyfile(domain_src, domain_path)
        _debug(f"  copied domain to: {domain_path}", debug)
    except Exception as e:
        _debug(f"  failed to copy domain: {e}", debug)
        domain_path = domain_src

    # Run solver
    _debug("Running solver...", debug)
    result = solver.solve(
        domain_path, 
        problem_path, 
        pddl_dir,
        time_limit=time_limit,
        verbose=verbose,
        debug=debug
    )
    _debug(f"Solver result: success={result.get('success')}", debug)
    
    # If solution found, parse the plan
    if result.get('success') and result.get('plans'):
        _debug(f"Solution found! Plans: {result.get('plans')}", debug)
        for plan_file in result['plans']:
            parsed_actions = solver.parse_plan(plan_file)
            result['parsed_plan'] = parsed_actions
            _debug(f"Parsed {len(parsed_actions)} actions from plan", debug)
            break  # Just parse first plan
    else:
        _debug(f"No solution found or no plans generated", debug)
        if result.get('error'):
            _debug(f"  error: {result.get('error')}", debug)
    
    return {
        "plan": plan.__dict__,
        "powerlifted": result,
        "pddl": {
            "domain": domain_path,
            "problem": problem_path
        }
    }


def synthesize_from_facts(bug_id: str, goal: str,
                          facts: Dict[str, Any],
                          chainreactor_path: Optional[str] = None,
                          output_dir: Optional[str] = None,
                          verbose: bool = False,
                          time_limit: Optional[int] = None,
                          debug: bool = False) -> Dict[str, Any]:
    """
    Synthesize exploit plan from pre-extracted system facts.
    
    This is useful when you have already extracted system information
    (users, groups, executables, permissions) and want to generate
    a more targeted PDDL problem.
    
    Args:
        bug_id: Bug identifier
        goal: Goal description
        facts: Dictionary with system facts (users, groups, executables, etc.)
        chainreactor_path: Path to chainreactor repo
        output_dir: Directory for output files
        verbose: Print planner output
        time_limit: Planner time limit
        
    Returns:
        Dictionary with plan and solver results
    """
    _debug(f"synthesize_from_facts called: bug_id={bug_id}, goal={goal}", debug)
    _debug(f"  facts keys: {list(facts.keys())}", debug)
    
    # Resolve chainreactor path
    if not chainreactor_path:
        try:
            src_root = Path(__file__).resolve().parents[2]
            cr_candidate = src_root / 'chainreactor'
            if cr_candidate.exists():
                chainreactor_path = str(cr_candidate)
        except Exception:
            pass
    
    if not chainreactor_path or not Path(chainreactor_path).exists():
        _debug(f"chainreactor path not found: {chainreactor_path}", debug)
        return {
            "success": False,
            "error": "chainreactor path not found"
        }
    
    _debug(f"Using chainreactor path: {chainreactor_path}", debug)
    
    # Setup output directory
    if not output_dir:
        output_dir = os.path.join(os.getcwd(), f'synth_{bug_id}')
    os.makedirs(output_dir, exist_ok=True)
    
    pddl_dir = os.path.join(output_dir, 'pddl')
    os.makedirs(pddl_dir, exist_ok=True)
    _debug(f"PDDL dir: {pddl_dir}", debug)
    
    # Generate PDDL
    gen = PDDLGenerator(chainreactor_path)
    _debug("PDDLGenerator created", debug)
    
    try:
        domain_src = gen.domain_path()
    except (RuntimeError, FileNotFoundError) as e:
        return {"success": False, "error": str(e)}
    
    problem_path = gen.generate_problem_from_facts(
        f"{bug_id}-facts",
        facts,
        os.path.join(pddl_dir, 'problem.pddl'),
        goal
    )
    _debug(f"Problem generated: {problem_path}", debug)
    
    # Copy domain
    try:
        import shutil
        domain_path = os.path.join(pddl_dir, 'domain.pddl')
        shutil.copyfile(domain_src, domain_path)
    except Exception:
        domain_path = domain_src
    
    # Solve
    solver = PowerliftedSolver(debug=debug)
    _debug(f"PowerliftedSolver created, available={solver.available()}", debug)
    if not solver.available():
        _debug("Powerlifted not available!", debug)
        return {
            "success": False,
            "error": "Powerlifted not available",
            "pddl": {"domain": domain_path, "problem": problem_path}
        }
    
    _debug("Running solver...", debug)
    result = solver.solve(
        domain_path,
        problem_path,
        pddl_dir,
        time_limit=time_limit,
        verbose=verbose,
        debug=debug
    )
    _debug(f"Solver result: success={result.get('success')}", debug)
    
    if result.get('success') and result.get('plans'):
        _debug(f"Solution found! Parsing plan...", debug)
        for plan_file in result['plans']:
            result['parsed_plan'] = solver.parse_plan(plan_file)
            _debug(f"Parsed {len(result['parsed_plan'])} actions", debug)
            break
    else:
        _debug("No solution found or no plans", debug)
    
    return {
        "success": result.get('success', False),
        "powerlifted": result,
        "pddl": {"domain": domain_path, "problem": problem_path}
    }
